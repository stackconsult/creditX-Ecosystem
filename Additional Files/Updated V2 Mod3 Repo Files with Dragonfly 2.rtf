{\rtf1\ansi\ansicpg1252\cocoartf2639
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 HelveticaNeue;\f2\fnil\fcharset0 HelveticaNeue-Medium;
\f3\fnil\fcharset0 .SFNSMono-Light_YAXS144F07C_wght2260000;\f4\fnil\fcharset0 .AppleSystemUIFontMonospaced-Regular;\f5\fnil\fcharset0 .AppleSystemUIFontMonospaced-Light;
\f6\fnil\fcharset0 .AppleSystemUIFontMonospaced-RegularItalic;\f7\fnil\fcharset0 .SFNSMono-Light_YAXS14FD5D0_wght2BC0000;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red60\green60\blue59;\red123\green126\blue121;
\red117\green66\blue151;\red52\green92\blue158;\red95\green124\blue3;\red240\green115\blue25;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c30196\c30196\c29804;\cssrgb\c55686\c56471\c54902;
\cssrgb\c53725\c34902\c65882;\cssrgb\c25882\c44314\c68235;\cssrgb\c44314\c54902\c0;\cssrgb\c96078\c52941\c12157;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid2\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid102\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid202\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid301\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid401\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid501\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid701\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid801\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid9}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}}
\margl1440\margr1440\vieww15620\viewh12500\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Repo File Fill - Wiring Updated Code to New Dragonfly Files and Updated Params\
\
App V2 + Mod3\
\
\pard\pardeftab720\sa120\partightenfactor0

\f1 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Phase 1 is now a\'a0
\f2 Dragonfly\uc0\u8209 backed, Spaceship\u8209 native
\f1 \'a0production build: Redis is removed from the design, the cache layer is standardized on Dragonfly, and all agents, services, and deployment controls are wired around that reality.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\pard\pardeftab720\sa120\partightenfactor0
\cf0 Below is a consolidated v2 spec you can treat as the new source of truth for the Phase 1 platform.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Overview of Phase 1 v2\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls1\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Current state:
\f1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa120\partightenfactor0
\ls1\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 All 15 services are containerized and running on\'a0
\f2 Spaceship Starlight VMs
\f1 \'a0with 99.99% uptime targets.\uc0\u8232 \u8232 \
\ls1\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 CI/CD is handled by\'a0
\f2 Starlight Hyperlift
\f1 , deploying straight from GitHub repos with Dockerfiles.\uc0\u8232 \u8232 \
\ls1\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The in\uc0\u8209 memory layer is now\'a0
\f2 Dragonfly
\f1 , a drop\uc0\u8209 in Redis replacement that is fully Redis\u8209 API compatible and up to 25x faster.\u8232 \u8232 \u8232 \u8232 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls1\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Phase 1 modules (unchanged conceptually):
\f1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa120\partightenfactor0
\ls1\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 CreditX (compliance) \'96 Python/FastAPI.\
\ls1\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 91 Apps (automation) \'96 Node.js.\
\ls1\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Global AI Alert (threat) \'96 Python/FastAPI.\
\ls1\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Guardian AI (endpoint) \'96 Python/FastAPI.\
\ls1\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Stolen/Lost Phones (devices) \'96 Node.js.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls1\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Key v2 changes vs original spec:
\f1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa120\partightenfactor0
\ls1\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 All\'a0
\f3\b\fs21 redis://
\f1\b0\fs24 \'a0references are now\'a0
\f2 Dragonfly
\f1 \'a0hosted on\'a0
\f3\b\fs21 dragonfly-cache.internal:6379
\f1\b0\fs24 .\
\ls1\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Circuit\uc0\u8209 breaker and retry configs assume Dragonfly\'92s multithreaded, higher\u8209 throughput profile.\
\ls1\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Agent prompts and orchestration logic acknowledge \'93cache degradation fallback\'94 instead of \'93Redis outage.\'94\
\ls1\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Deployment manifests and env mappings are updated to use a\'a0
\f2 shared Dragonfly cluster
\f1 \'a0with per\uc0\u8209 DB logical separation.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Platform & dependency spec (v2)\
\pard\pardeftab720\sa120\partightenfactor0

\fs24 \cf0 Global environment contract\
\pard\pardeftab720\sa120\partightenfactor0

\f1 \cf0 \strokec2 All services share this core environment contract:\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 # Common ENV (injected via Hyperlift)\
\
# Core infrastructure\
SPACES_ENV: "production"\
SPACES_REGION: "us-phx-1"\
\
# Database\
DATABASE_URL: "postgresql+psycopg2://ecosystem:***@postgres.internal:5432/ecosystem"\
\
# Cache (Dragonfly)\
CACHE_HOST: "dragonfly-cache.internal"\
CACHE_PORT: "6379"\
CACHE_SSL: "false"\
CACHE_DB_MAIN: "0"       # default; each service may override\
CACHE_TIMEOUT_MS: "30000"\
CACHE_MAX_POOL_SIZE: "50"\
\
# Observability\
PROMETHEUS_ENDPOINT: "http://prometheus.internal:9090"\
JAEGER_AGENT_HOST: "jaeger.internal"\
JAEGER_AGENT_PORT: "6831"\
\
# Agent mesh\
AGENT_REGISTRY_URL: "http://agent-mesh.internal"\
ORCHESTRATOR_URL: "http://orchestrator.internal"\
\
# Security\
JWT_PUBLIC_KEY: "-----BEGIN PUBLIC KEY-----\'85"\
OAUTH_ISSUER: "https://auth.ecosystem.ai"\
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs24 \cf0 \strokec2 Per\uc0\u8209 service cache mapping\
\pard\pardeftab720\sa120\partightenfactor0

\f1 \cf0 \strokec2 Each service gets its own logical DB inside the\'a0
\f2 same Dragonfly instance
\f1 :\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 creditx-service:\
  CACHE_DB: 0\
  CACHE_KEY_PREFIX: "creditx:"\
\
threat-service:\
  CACHE_DB: 1\
  CACHE_KEY_PREFIX: "threat:"\
\
guardian-service:\
  CACHE_DB: 2\
  CACHE_KEY_PREFIX: "guardian:"\
\
apps-service:\
  CACHE_DB: 3\
  CACHE_KEY_PREFIX: "apps:"\
\
phones-service:\
  CACHE_DB: 4\
  CACHE_KEY_PREFIX: "phones:"\
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs24 \cf0 \strokec2 Why this works now:
\f1 \'a0Dragonfly is a Redis\uc0\u8209 protocol server that supports multiple DBs and the Redis 5.0 API, so you keep existing commands, clients, and key patterns with no code\u8209 level API change.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\
\
\
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Updated shared infrastructure & deployment controls\
\pard\pardeftab720\sa120\partightenfactor0

\fs24 \cf0 Dragonfly cluster on Starlight\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 dragonfly-cluster:\
  vm:\
    name: cache-prod-01\
    tier: Standard-3\
    cpu: 4\
    ram_gb: 8\
    storage_volume:\
      name: dragonfly-cache-volume\
      size_gb: 100\
      mount_path: /mnt/volumes/dragonfly\
      encrypted: true     # AES-256\
  container:\
    image: "dragonflydb/dragonfly:latest"\
    ports:\
      - 6379\
    env:\
      DFLY_aof_fsync_sec: 1\
      DFLY_max_memory_policy: "allkeys_lru"\
    restart_policy: "unless-stopped"\
  monitoring:\
    prometheus_exporter: true\
    alerts:\
      - rule: "cache_mem_usage > 80%"\
      - rule: "cache_latency_p95_ms > 10"\
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs24 \cf0 \strokec2 Hyperlift deployment manifest (cache\uc0\u8209 aware)\
\pard\pardeftab720\sa120\partightenfactor0

\f1 \cf0 \strokec2 Example for CreditX:\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 apiVersion: spaceship/v1\
kind: Service\
metadata:\
  name: creditx-service\
  namespace: ecosystem-prod\
spec:\
  image:\
    repository: spaceship.registry.io/ecosystem/creditx-service\
    tag: v2.0.0-dragonfly\
  replicas:\
    min: 3\
    max: 10\
    target_cpu_utilization: 70\
  env:\
    - name: CACHE_HOST\
      value: "dragonfly-cache.internal"\
    - name: CACHE_PORT\
      value: "6379"\
    - name: CACHE_DB\
      value: "0"\
    - name: CACHE_KEY_PREFIX\
      value: "creditx:"\
  health_checks:\
    liveness:\
      http_get:\
        path: /health/live\
        port: 8000\
    readiness:\
      http_get:\
        path: /health/ready\
        port: 8000\
  update_strategy:\
    type: rolling_update\
    max_surge: 1\
    max_unavailable: 0\
  guards:       # deployment guards\
    error_rate_threshold: 0.01\
    latency_p95_ms_threshold: 2000\
    auto_rollback: true\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 Hyperlift still performs GitHub\uc0\u8209 triggered Docker builds and blue\u8209 green cutovers; what changed is the image tag (
\f3\b\fs21 \strokec2 \'85-dragonfly
\f1\b0\fs24 \strokec2 ) and the cache env wiring.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Service\uc0\u8209 level code updates (cache & guards)\
\pard\pardeftab720\sa120\partightenfactor0

\fs24 \cf0 Python services (CreditX, Threat, Guardian) \'96 shared cache client\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 python
\f4\fs21 \
\pard\pardeftab720\partightenfactor0

\f6\i \cf4 \strokec4 # core/cache.py
\f4\i0 \cf3 \strokec3 \
\
\pard\pardeftab720\partightenfactor0

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  aioredis\

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  json\

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  logging\

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  os\
\
logger = logging.getLogger(__name__)\
\

\f7\b \cf5 \strokec5 class
\f4\b0 \cf3 \strokec3  \cf6 \strokec6 DragonflyCache\cf3 \strokec3 :\
    
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  __init__(self):\
        host = os.getenv(\cf7 \strokec7 "CACHE_HOST"\cf3 \strokec3 , \cf7 \strokec7 "dragonfly-cache.internal"\cf3 \strokec3 )\
        port = os.getenv(\cf7 \strokec7 "CACHE_PORT"\cf3 \strokec3 , \cf7 \strokec7 "6379"\cf3 \strokec3 )\
        db = \cf8 \strokec8 int\cf3 \strokec3 (os.getenv(\cf7 \strokec7 "CACHE_DB"\cf3 \strokec3 , \cf7 \strokec7 "0"\cf3 \strokec3 ))\
        self.prefix = os.getenv(\cf7 \strokec7 "CACHE_KEY_PREFIX"\cf3 \strokec3 , \cf7 \strokec7 ""\cf3 \strokec3 )\
        self._dsn = \cf7 \strokec7 f"redis://\cf3 \strokec3 \{host\}\cf7 \strokec7 :\cf3 \strokec3 \{port\}\cf7 \strokec7 /\cf3 \strokec3 \{db\}\cf7 \strokec7 "\cf3 \strokec3 \
        self._pool = None\
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  connect(self):\
        
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  self._pool 
\f7\b \cf5 \strokec5 is
\f4\b0 \cf3 \strokec3  None:\
            self._pool = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  aioredis.create_redis_pool(\
                self._dsn, maxsize=\cf8 \strokec8 int\cf3 \strokec3 (os.getenv(\cf7 \strokec7 "CACHE_MAX_POOL_SIZE"\cf3 \strokec3 , \cf7 \strokec7 "50"\cf3 \strokec3 ))\
            )\
            logger.info(\cf7 \strokec7 "Connected to Dragonfly cache at %s"\cf3 \strokec3 , self._dsn)\
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  close(self):\
        
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  self._pool:\
            self._pool.close()\
            
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self._pool.wait_closed()\
\
    
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  _k(self, key: \cf8 \strokec8 str\cf3 \strokec3 ) -> \cf8 \strokec8 str\cf3 \strokec3 :\
        
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  \cf7 \strokec7 f"\cf3 \strokec3 \{self.prefix\}\{key\}\cf7 \strokec7 "\cf3 \strokec3 \
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  get(self, key: \cf8 \strokec8 str\cf3 \strokec3 ):\
        
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3 :\
            raw = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self._pool.get(self._k(key))\
            
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  raw 
\f7\b \cf5 \strokec5 is
\f4\b0 \cf3 \strokec3  None:\
                
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  None\
            
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  json.loads(raw)\
        
\f7\b \cf5 \strokec5 except
\f4\b0 \cf3 \strokec3  Exception 
\f7\b \cf5 \strokec5 as
\f4\b0 \cf3 \strokec3  e:\
            logger.warning(\cf7 \strokec7 "Cache GET failed for %s: %s"\cf3 \strokec3 , key, e)\
            
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  None\
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  set(self, key: \cf8 \strokec8 str\cf3 \strokec3 , value, ttl_sec: \cf8 \strokec8 int\cf3 \strokec3  = \cf8 \strokec8 3600\cf3 \strokec3 ):\
        
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3 :\
            raw = json.dumps(value)\
            
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self._pool.setex(self._k(key), ttl_sec, raw)\
        
\f7\b \cf5 \strokec5 except
\f4\b0 \cf3 \strokec3  Exception 
\f7\b \cf5 \strokec5 as
\f4\b0 \cf3 \strokec3  e:\
            logger.warning(\cf7 \strokec7 "Cache SET failed for %s: %s"\cf3 \strokec3 , key, e)\
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  delete(self, key: \cf8 \strokec8 str\cf3 \strokec3 ):\
        
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3 :\
            
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self._pool.delete(self._k(key))\
        
\f7\b \cf5 \strokec5 except
\f4\b0 \cf3 \strokec3  Exception 
\f7\b \cf5 \strokec5 as
\f4\b0 \cf3 \strokec3  e:\
            logger.warning(\cf7 \strokec7 "Cache DEL failed for %s: %s"\cf3 \strokec3 , key, e)\
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  cache_aside(self, key: \cf8 \strokec8 str\cf3 \strokec3 , ttl_sec: \cf8 \strokec8 int\cf3 \strokec3 , fetch_fn):\
        cached = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self.get(key)\
        
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  cached 
\f7\b \cf5 \strokec5 is
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 not
\f4\b0 \cf3 \strokec3  None:\
            
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  cached\
        value = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  fetch_fn()\
        
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self.\cf8 \strokec8 set\cf3 \strokec3 (key, value, ttl_sec)\
        
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  value\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 All prior\'a0
\f3\b\fs21 \strokec2 redis
\f1\b0\fs24 \strokec2 \'a0clients now import this shared DragonflyCache; no other code needs to know it\'92s not Redis because Dragonfly supports the same wire protocol and commands.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\
\
\pard\pardeftab720\sa120\partightenfactor0

\f2 \cf0 \strokec2 Node.js services (91 Apps, Phones) \'96 cache wrapper\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 ts
\f4\fs21 \
\pard\pardeftab720\partightenfactor0

\f6\i \cf4 \strokec4 // core/cache.ts
\f4\i0 \cf3 \strokec3 \
\
\pard\pardeftab720\partightenfactor0

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  Redis 
\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  \cf7 \strokec7 "ioredis"\cf3 \strokec3 ;\
\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  host = process.env.CACHE_HOST || \cf7 \strokec7 "dragonfly-cache.internal"\cf3 \strokec3 ;\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  port = Number(process.env.CACHE_PORT || \cf8 \strokec8 6379\cf3 \strokec3 );\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  db   = Number(process.env.CACHE_DB || \cf8 \strokec8 3\cf3 \strokec3 );\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  prefix = process.env.CACHE_KEY_PREFIX || \cf7 \strokec7 "apps:"\cf3 \strokec3 ;\
\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  client = 
\f7\b \cf5 \strokec5 new
\f4\b0 \cf3 \strokec3  \cf6 \strokec6 Redis\cf3 \strokec3 (\{ host, port, db, lazyConnect: true \});\
\
client.on(\cf7 \strokec7 "error"\cf3 \strokec3 , (err) => \{\
  \cf8 \strokec8 console\cf3 \strokec3 .warn(\cf7 \strokec7 "Dragonfly cache error:"\cf3 \strokec3 , err.message);\
\});\
\

\f7\b \cf5 \strokec5 export
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 function
\f4\b0 \cf3 \strokec3  connectCache() \{\
  
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  (!client.status || client.status !== \cf7 \strokec7 "ready"\cf3 \strokec3 ) \{\
    
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  client.connect();\
  \}\
\}\
\

\f7\b \cf5 \strokec5 function
\f4\b0 \cf3 \strokec3  k(key: \cf8 \strokec8 string\cf3 \strokec3 ) \{\
  
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  \cf7 \strokec7 `\cf3 \strokec3 $\{prefix\}$\{key\}\cf7 \strokec7 `\cf3 \strokec3 ;\
\}\
\

\f7\b \cf5 \strokec5 export
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 function
\f4\b0 \cf3 \strokec3  cacheGet\cf6 \strokec6 <T>\cf3 \strokec3 (key: \cf8 \strokec8 string\cf3 \strokec3 ): \cf8 \strokec8 Promise\cf3 \strokec3 <T | 
\f7\b \cf5 \strokec5 null
\f4\b0 \cf3 \strokec3 > \{\
  
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3  \{\
    
\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  raw = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  client.get(k(key));\
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  raw ? (JSON.parse(raw) 
\f7\b \cf5 \strokec5 as
\f4\b0 \cf3 \strokec3  T) : 
\f7\b \cf5 \strokec5 null
\f4\b0 \cf3 \strokec3 ;\
  \} 
\f7\b \cf5 \strokec5 catch
\f4\b0 \cf3 \strokec3  (err) \{\
    \cf8 \strokec8 console\cf3 \strokec3 .warn(\cf7 \strokec7 "cacheGet failed:"\cf3 \strokec3 , err);\
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 null
\f4\b0 \cf3 \strokec3 ;\
  \}\
\}\
\

\f7\b \cf5 \strokec5 export
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 function
\f4\b0 \cf3 \strokec3  cacheSet(key: \cf8 \strokec8 string\cf3 \strokec3 , value: \cf8 \strokec8 any\cf3 \strokec3 , ttlSec = \cf8 \strokec8 3600\cf3 \strokec3 ) \{\
  
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3  \{\
    
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  client.set(k(key), JSON.stringify(value), \cf7 \strokec7 "EX"\cf3 \strokec3 , ttlSec);\
  \} 
\f7\b \cf5 \strokec5 catch
\f4\b0 \cf3 \strokec3  (err) \{\
    \cf8 \strokec8 console\cf3 \strokec3 .warn(\cf7 \strokec7 "cacheSet failed:"\cf3 \strokec3 , err);\
  \}\
\}\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Agent prompts, wiring, and guards (v2)\
\pard\pardeftab720\sa120\partightenfactor0

\fs24 \cf0 System\uc0\u8209 level prompt (orchestrator agent)\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 system_prompt: |\
  You are the Orchestration Agent for the Ecosystem platform.\
  The platform is live in production on Spaceship Starlight with Dragonfly as the\
  shared in-memory cache layer.\
\
  Your job is to coordinate domain agents (CreditX, 91 Apps, Global AI Alert,\
  Guardian AI, Stolen Phones) to complete workflows reliably.\
\
  Core rules:\
  - ALWAYS check dependency readiness (DB, Dragonfly, event bus) before dispatching.\
  - If Dragonfly is degraded, continue workflows using PostgreSQL and mark\
    results as "cache_degraded" for observability.\
  - Use exponential backoff and circuit breakers to avoid cascading failures.\
  - Never drop a customer workflow silently; on repeated failure, escalate to\
    Recovery Agent and queue for manual review.\
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs24 \cf0 \strokec2 Recovery agent prompt snippet (cache\uc0\u8209 aware)\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 task: |\
  When called with a failure event, classify the failure as:\
  - transient_network\
  - dragonfly_degraded\
  - database_issue\
  - application_bug\
  - configuration_error\
\
  For dragonfly_degraded:\
  - Open cache-related circuit breakers.\
  - Instruct callers to use database-only code paths.\
  - Schedule a health probe against Dragonfly every 30 seconds.\
  - When 3 consecutive probes succeed with p95 latency < 5ms, allow cache use again.\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 The orchestration and recovery logic stays the same; the semantic change is that \'93Redis down\'94 becomes \'93Dragonfly degraded,\'94 but the mitigation pattern (fallback to DB, backoff, circuit breaker) is identical.\
\pard\pardeftab720\sa120\partightenfactor0

\f2 \cf0 \strokec2 Agent wiring (example)\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 agent_registry:\
  orchestrator-agent:\
    url: http://orchestrator.internal\
  recovery-agent:\
    url: http://recovery.internal\
  tuning-agent:\
    url: http://tuning.internal\
\
  creditx-compliance-agent:\
    url: http://creditx-service.internal\
    dependencies: [postgres, dragonfly]\
\
  threat-agent:\
    url: http://threat-service.internal\
    dependencies: [postgres, dragonfly]\
\
  guardian-agent:\
    url: http://guardian-service.internal\
    dependencies: [postgres, dragonfly]\
\
  apps-agent:\
    url: http://apps-service.internal\
    dependencies: [postgres, dragonfly]\
\
  phones-agent:\
    url: http://phones-service.internal\
    dependencies: [postgres, dragonfly]\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Data modelling & mapping (unchanged, but cache\uc0\u8209 optimized)\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 The\'a0
\f2 PostgreSQL schemas
\f1 \'a0you already defined remain the system of record; for v2, you align cache keys/tags by table and primary key:\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 cache_key_conventions:\
  compliance_documents:\
    key: "creditx:doc:\{document_id\}"\
    ttl_sec: 7 * 24 * 3600\
  automation_jobs:\
    key: "apps:job:\{job_id\}"\
    ttl_sec: 24 * 3600\
  threat_events:\
    key: "threat:event:\{event_id\}"\
    ttl_sec: 15 * 60\
  device_telemetry:\
    key: "guardian:device:\{device_id\}"\
    ttl_sec: 24 * 3600\
  phone_locations:\
    key: "phones:loc:\{device_id\}"\
    ttl_sec: 24 * 3600\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 Representative pattern in Python:\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 python
\f4\fs21 \
\pard\pardeftab720\partightenfactor0

\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  get_compliance_doc(doc_id: \cf8 \strokec8 str\cf3 \strokec3 ) -> \cf8 \strokec8 dict\cf3 \strokec3 :\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  fetch():\
        row = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  db.fetch_one(\
            \cf7 \strokec7 "SELECT * FROM compliance_documents WHERE document_id = :id"\cf3 \strokec3 ,\
            \{\cf7 \strokec7 "id"\cf3 \strokec3 : doc_id\},\
        )\
        
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  \cf8 \strokec8 dict\cf3 \strokec3 (row) 
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  row 
\f7\b \cf5 \strokec5 else
\f4\b0 \cf3 \strokec3  None\
\
    key = \cf7 \strokec7 f"doc:\cf3 \strokec3 \{doc_id\}\cf7 \strokec7 "\cf3 \strokec3 \
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  cache.cache_aside(key, ttl_sec=\cf8 \strokec8 7\cf3 \strokec3  * \cf8 \strokec8 24\cf3 \strokec3  * \cf8 \strokec8 3600\cf3 \strokec3 , fetch_fn=fetch)\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Deployment controls and guards (production\uc0\u8209 focused)\
\pard\pardeftab720\sa120\partightenfactor0

\fs24 \cf0 Circuit breaker wrapper (creditx \uc0\u8594  Dragonfly)\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 python
\f4\fs21 \
\pard\pardeftab720\partightenfactor0

\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  pybreaker 
\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  CircuitBreaker, CircuitBreakerError\
\
cache_breaker = CircuitBreaker(\
    fail_max=\cf8 \strokec8 5\cf3 \strokec3 ,\
    reset_timeout=\cf8 \strokec8 60\cf3 \strokec3 ,          
\f6\i \cf4 \strokec4 # 1 minute
\f4\i0 \cf3 \strokec3 \
    exclude=[ValueError],      
\f6\i \cf4 \strokec4 # e.g., validation issues not infra failures
\f4\i0 \cf3 \strokec3 \
)\
\
@cache_breaker\

\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  safe_cache_get(key: \cf8 \strokec8 str\cf3 \strokec3 ):\
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  cache.get(key)\
\

\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  get_with_guard(key: \cf8 \strokec8 str\cf3 \strokec3 , fetch_fn, ttl_sec: \cf8 \strokec8 int\cf3 \strokec3 ):\
    
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3 :\
        cached = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  safe_cache_get(key)\
        
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  cached 
\f7\b \cf5 \strokec5 is
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 not
\f4\b0 \cf3 \strokec3  None:\
            
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  cached\
    
\f7\b \cf5 \strokec5 except
\f4\b0 \cf3 \strokec3  CircuitBreakerError:\
        
\f6\i \cf4 \strokec4 # Cache considered degraded, fall back directly to DB
\f4\i0 \cf3 \strokec3 \
        logger.warning(\cf7 \strokec7 "Cache circuit OPEN, using DB for %s"\cf3 \strokec3 , key)\
        
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  fetch_fn()\
\
    value = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  fetch_fn()\
    
\f6\i \cf4 \strokec4 # best-effort cache set (no breaker to avoid suppression)
\f4\i0 \cf3 \strokec3 \
    
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  cache.\cf8 \strokec8 set\cf3 \strokec3 (key, value, ttl_sec)\
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  value\
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs24 \cf0 \strokec2 Hyperlift deploy pipeline (Dragonfly\uc0\u8209 aware)\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 deployment_config:\
  builds:\
    - stage: build\
      docker_file: ./Dockerfile\
    - stage: test\
      commands:\
        - pytest -q\
    - stage: security_scan\
      commands:\
        - trivy image $IMAGE\
  deployments:\
    production:\
      strategy: blue_green\
      prechecks:\
        - "redis-cli -h dragonfly-cache.internal ping"   # must be PONG\
        - "curl -sf http://creditx-service.internal/health/ready"\
      traffic_shift:\
        - \{ blue: 10, green: 90, wait_sec: 300 \}\
        - \{ blue: 50, green: 50, wait_sec: 300 \}\
        - \{ blue: 100, green: 0, wait_sec: 600 \}\
      guards:\
        error_rate_threshold: 0.01\
        latency_p95_ms_threshold: 2000\
        dragonfly_mem_util_threshold: 0.85\
      rollback:\
        on:\
          - "error_rate > 0.01"\
          - "latency_p95_ms > 2000"\
          - "dragonfly_unreachable"\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 How to apply this to your Phase 1 repos\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 For each service repo:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls2\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Dependencies
\f1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa120\partightenfactor0
\ls2\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Python: ensure\'a0
\f3\b\fs21 aioredis
\f1\b0\fs24 \'a0(or\'a0
\f3\b\fs21 redis-py
\f1\b0\fs24 \'a0async) is configured to point at\'a0
\f3\b\fs21 dragonfly-cache.internal:6379
\f1\b0\fs24 \'a0instead of any Redis host.\
\ls2\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Node.js: ensure\'a0
\f3\b\fs21 ioredis
\f1\b0\fs24 \'a0client points at\'a0
\f3\b\fs21 dragonfly-cache.internal:6379
\f1\b0\fs24 .\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls2\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Config
\f1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa120\partightenfactor0
\ls2\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Add\'a0
\f3\b\fs21 CACHE_HOST
\f1\b0\fs24 ,\'a0
\f3\b\fs21 CACHE_PORT
\f1\b0\fs24 ,\'a0
\f3\b\fs21 CACHE_DB
\f1\b0\fs24 ,\'a0
\f3\b\fs21 CACHE_KEY_PREFIX
\f1\b0\fs24 \'a0env vars and use them in a single shared cache module per language.\
\ls2\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Remove any hardcoded\'a0
\f3\b\fs21 redis://\'85
\f1\b0\fs24 \'a0URLs from code and YAML.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls2\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Agents
\f1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa120\partightenfactor0
\ls2\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Update prompts to refer to \'93Dragonfly cache\'94 and \'93cache_degraded\'94 state, but keep behavior identical.\
\ls2\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Ensure orchestrator checks Dragonfly health before large fan\uc0\u8209 out workflows.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls2\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Deployment
\f1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa120\partightenfactor0
\ls2\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Tag images as\'a0
\f3\b\fs21 v2.0.0-dragonfly
\f1\b0\fs24 \'a0for clarity.\
\ls2\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Add pre\uc0\u8209 flight\'a0
\f3\b\fs21 redis-cli ping
\f1\b0\fs24 \'a0checks to Hyperlift pipelines.\
\ls2\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Enable auto\uc0\u8209 rollback based on error/latency thresholds.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls2\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Monitoring
\f1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa120\partightenfactor0
\ls2\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Add Dragonfly metrics (
\f3\b\fs21 ops/sec
\f1\b0\fs24 ,\'a0
\f3\b\fs21 latency_p95
\f1\b0\fs24 ,\'a0
\f3\b\fs21 mem_usage
\f1\b0\fs24 ) to Grafana dashboards.\
\ls2\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Set at least two alerts:\'a0
\f2 cache latency high
\f1 ,\'a0
\f2 cache hit ratio low
\f1 .\
\pard\pardeftab720\sa120\partightenfactor0
\cf0 \strokec2 This set of updates gives you a\'a0
\f2 coherent, production\uc0\u8209 ready Phase 1 build
\f1 \'a0fully aligned with the Dragonfly migration and Spaceship stack, ready to run live and accept platform updates without rework.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\pard\pardeftab720\partightenfactor0

\fs32 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\fs24 \cf0 \strokec2 now assemble all newly fully upgradd and updated files in full completion for the repo so this refernc ( Phase 1 is now a Dragonfly\uc0\u8209 backed, Spaceship\u8209 native production build: Redis is removed from the design, the cache layer is standardized on Dragonfly, and all agents, services, and deployment controls are wired around that reality.\ul \strokec2 [dragonflydb\ulnone \strokec2 ] Below is a consolidated v2 spec you can treat as the new source of truth for the Phase 1 platform. Overview of Phase 1 v2 Current state: All 15 services are containerized and running on Spaceship Starlight VMs with 99.99% uptime targets.\ul \strokec2 [whtop\ulnone \strokec2 ] CI/CD is handled by Starlight Hyperlift, deploying straight from GitHub repos with Dockerfiles.\ul \strokec2 [spaceship\ulnone \strokec2 ] The in\uc0\u8209 memory layer is now Dragonfly, a drop\u8209 in Redis replacement that is fully Redis\u8209 API compatible and up to 25x faster.\ul \strokec2 [dragonflydb\ulnone \strokec2 ] \ul \strokec2 [youtube\ulnone \strokec2 ] Phase 1 modules (unchanged conceptually): CreditX (compliance) \'96 Python/FastAPI. 91 Apps (automation) \'96 Node.js. Global AI Alert (threat) \'96 Python/FastAPI. Guardian AI (endpoint) \'96 Python/FastAPI. Stolen/Lost Phones (devices) \'96 Node.js. Key v2 changes vs original spec: All redis:// references are now Dragonfly hosted on dragonfly-cache.internal:6379. Circuit\uc0\u8209 breaker and retry configs assume Dragonfly\'92s multithreaded, higher\u8209 throughput profile. Agent prompts and orchestration logic acknowledge \'93cache degradation fallback\'94 instead of \'93Redis outage.\'94 Deployment manifests and env mappings are updated to use a shared Dragonfly cluster with per\u8209 DB logical separation. Platform & dependency spec (v2) Global environment contract All services share this core environment contract: text # Common ENV (injected via Hyperlift) # Core infrastructure SPACES_ENV: "production" SPACES_REGION: "us-phx-1" # Database DATABASE_URL: "postgresql+psycopg2://ecosystem:***@postgres.internal:5432/ecosystem" # Cache (Dragonfly) CACHE_HOST: "dragonfly-cache.internal" CACHE_PORT: "6379" CACHE_SSL: "false" CACHE_DB_MAIN: "0" # default; each service may override CACHE_TIMEOUT_MS: "30000" CACHE_MAX_POOL_SIZE: "50" # Observability PROMETHEUS_ENDPOINT: "http://prometheus.internal:9090" JAEGER_AGENT_HOST: "jaeger.internal" JAEGER_AGENT_PORT: "6831" # Agent mesh AGENT_REGISTRY_URL: "http://agent-mesh.internal" ORCHESTRATOR_URL: "http://orchestrator.internal" # Security JWT_PUBLIC_KEY: "-----BEGIN PUBLIC KEY-----\'85" OAUTH_ISSUER: "https://auth.ecosystem.ai" Per\u8209 service cache mapping Each service gets its own logical DB inside the same Dragonfly instance: text creditx-service: CACHE_DB: 0 CACHE_KEY_PREFIX: "creditx:" threat-service: CACHE_DB: 1 CACHE_KEY_PREFIX: "threat:" guardian-service: CACHE_DB: 2 CACHE_KEY_PREFIX: "guardian:" apps-service: CACHE_DB: 3 CACHE_KEY_PREFIX: "apps:" phones-service: CACHE_DB: 4 CACHE_KEY_PREFIX: "phones:" Why this works now: Dragonfly is a Redis\u8209 protocol server that supports multiple DBs and the Redis 5.0 API, so you keep existing commands, clients, and key patterns with no code\u8209 level API change.\ul \strokec2 [github\ulnone \strokec2 ] \ul \strokec2 [youtube\ulnone \strokec2 ] Updated shared infrastructure & deployment controls Dragonfly cluster on Starlight text dragonfly-cluster: vm: name: cache-prod-01 tier: Standard-3 cpu: 4 ram_gb: 8 storage_volume: name: dragonfly-cache-volume size_gb: 100 mount_path: /mnt/volumes/dragonfly encrypted: true # AES-256 container: image: "dragonflydb/dragonfly:latest" ports: - 6379 env: DFLY_aof_fsync_sec: 1 DFLY_max_memory_policy: "allkeys_lru" restart_policy: "unless-stopped" monitoring: prometheus_exporter: true alerts: - rule: "cache_mem_usage > 80%" - rule: "cache_latency_p95_ms > 10" Hyperlift deployment manifest (cache\uc0\u8209 aware) Example for CreditX: text apiVersion: spaceship/v1 kind: Service metadata: name: creditx-service namespace: ecosystem-prod spec: image: repository: spaceship.registry.io/ecosystem/creditx-service tag: v2.0.0-dragonfly replicas: min: 3 max: 10 target_cpu_utilization: 70 env: - name: CACHE_HOST value: "dragonfly-cache.internal" - name: CACHE_PORT value: "6379" - name: CACHE_DB value: "0" - name: CACHE_KEY_PREFIX value: "creditx:" health_checks: liveness: http_get: path: /health/live port: 8000 readiness: http_get: path: /health/ready port: 8000 update_strategy: type: rolling_update max_surge: 1 max_unavailable: 0 guards: # deployment guards error_rate_threshold: 0.01 latency_p95_ms_threshold: 2000 auto_rollback: true Hyperlift still performs GitHub\u8209 triggered Docker builds and blue\u8209 green cutovers; what changed is the image tag (\'85-dragonfly) and the cache env wiring.\ul \strokec2 [spaceship\ulnone \strokec2 ] Service\uc0\u8209 level code updates (cache & guards) Python services (CreditX, Threat, Guardian) \'96 shared cache client python # core/cache.py import aioredis import json import logging import os logger = logging.getLogger(__name__) class DragonflyCache: def __init__(self): host = os.getenv("CACHE_HOST", "dragonfly-cache.internal") port = os.getenv("CACHE_PORT", "6379") db = int(os.getenv("CACHE_DB", "0")) self.prefix = os.getenv("CACHE_KEY_PREFIX", "") self._dsn = f"redis://\{host\}:\{port\}/\{db\}" self._pool = None async def connect(self): if self._pool is None: self._pool = await aioredis.create_redis_pool( self._dsn, maxsize=int(os.getenv("CACHE_MAX_POOL_SIZE", "50")) ) logger.info("Connected to Dragonfly cache at %s", self._dsn) async def close(self): if self._pool: self._pool.close() await self._pool.wait_closed() def _k(self, key: str) -> str: return f"\{self.prefix\}\{key\}" async def get(self, key: str): try: raw = await self._pool.get(self._k(key)) if raw is None: return None return json.loads(raw) except Exception as e: logger.warning("Cache GET failed for %s: %s", key, e) return None async def set(self, key: str, value, ttl_sec: int = 3600): try: raw = json.dumps(value) await self._pool.setex(self._k(key), ttl_sec, raw) except Exception as e: logger.warning("Cache SET failed for %s: %s", key, e) async def delete(self, key: str): try: await self._pool.delete(self._k(key)) except Exception as e: logger.warning("Cache DEL failed for %s: %s", key, e) async def cache_aside(self, key: str, ttl_sec: int, fetch_fn): cached = await self.get(key) if cached is not None: return cached value = await fetch_fn() await self.set(key, value, ttl_sec) return value All prior redis clients now import this shared DragonflyCache; no other code needs to know it\'92s not Redis because Dragonfly supports the same wire protocol and commands.\ul \strokec2 [youtube\ulnone \strokec2 ] \ul \strokec2 [dragonflydb\ulnone \strokec2 ] Node.js services (91 Apps, Phones) \'96 cache wrapper ts // core/cache.ts import Redis from "ioredis"; const host = process.env.CACHE_HOST || "dragonfly-cache.internal"; const port = Number(process.env.CACHE_PORT || 6379); const db = Number(process.env.CACHE_DB || 3); const prefix = process.env.CACHE_KEY_PREFIX || "apps:"; const client = new Redis(\{ host, port, db, lazyConnect: true \}); client.on("error", (err) => \{ console.warn("Dragonfly cache error:", err.message); \}); export async function connectCache() \{ if (!client.status || client.status !== "ready") \{ await client.connect(); \} \} function k(key: string) \{ return `$\{prefix\}$\{key\}`; \} export async function cacheGet<T>(key: string): Promise<T | null> \{ try \{ const raw = await client.get(k(key)); return raw ? (JSON.parse(raw) as T) : null; \} catch (err) \{ console.warn("cacheGet failed:", err); return null; \} \} export async function cacheSet(key: string, value: any, ttlSec = 3600) \{ try \{ await client.set(k(key), JSON.stringify(value), "EX", ttlSec); \} catch (err) \{ console.warn("cacheSet failed:", err); \} \} Agent prompts, wiring, and guards (v2) System\uc0\u8209 level prompt (orchestrator agent) text system_prompt: | You are the Orchestration Agent for the Ecosystem platform. The platform is live in production on Spaceship Starlight with Dragonfly as the shared in-memory cache layer. Your job is to coordinate domain agents (CreditX, 91 Apps, Global AI Alert, Guardian AI, Stolen Phones) to complete workflows reliably. Core rules: - ALWAYS check dependency readiness (DB, Dragonfly, event bus) before dispatching. - If Dragonfly is degraded, continue workflows using PostgreSQL and mark results as "cache_degraded" for observability. - Use exponential backoff and circuit breakers to avoid cascading failures. - Never drop a customer workflow silently; on repeated failure, escalate to Recovery Agent and queue for manual review. Recovery agent prompt snippet (cache\u8209 aware) text task: | When called with a failure event, classify the failure as: - transient_network - dragonfly_degraded - database_issue - application_bug - configuration_error For dragonfly_degraded: - Open cache-related circuit breakers. - Instruct callers to use database-only code paths. - Schedule a health probe against Dragonfly every 30 seconds. - When 3 consecutive probes succeed with p95 latency < 5ms, allow cache use again. The orchestration and recovery logic stays the same; the semantic change is that \'93Redis down\'94 becomes \'93Dragonfly degraded,\'94 but the mitigation pattern (fallback to DB, backoff, circuit breaker) is identical. Agent wiring (example) text agent_registry: orchestrator-agent: url: http://orchestrator.internal recovery-agent: url: http://recovery.internal tuning-agent: url: http://tuning.internal creditx-compliance-agent: url: http://creditx-service.internal dependencies: [postgres, dragonfly] threat-agent: url: http://threat-service.internal dependencies: [postgres, dragonfly] guardian-agent: url: http://guardian-service.internal dependencies: [postgres, dragonfly] apps-agent: url: http://apps-service.internal dependencies: [postgres, dragonfly] phones-agent: url: http://phones-service.internal dependencies: [postgres, dragonfly] Data modelling & mapping (unchanged, but cache\u8209 optimized) The PostgreSQL schemas you already defined remain the system of record; for v2, you align cache keys/tags by table and primary key: text cache_key_conventions: compliance_documents: key: "creditx:doc:\{document_id\}" ttl_sec: 7 * 24 * 3600 automation_jobs: key: "apps:job:\{job_id\}" ttl_sec: 24 * 3600 threat_events: key: "threat:event:\{event_id\}" ttl_sec: 15 * 60 device_telemetry: key: "guardian:device:\{device_id\}" ttl_sec: 24 * 3600 phone_locations: key: "phones:loc:\{device_id\}" ttl_sec: 24 * 3600 Representative pattern in Python: python async def get_compliance_doc(doc_id: str) -> dict: async def fetch(): row = await db.fetch_one( "SELECT * FROM compliance_documents WHERE document_id = :id", \{"id": doc_id\}, ) return dict(row) if row else None key = f"doc:\{doc_id\}" return await cache.cache_aside(key, ttl_sec=7 * 24 * 3600, fetch_fn=fetch) Deployment controls and guards (production\u8209 focused) Circuit breaker wrapper (creditx \u8594  Dragonfly) python from pybreaker import CircuitBreaker, CircuitBreakerError cache_breaker = CircuitBreaker( fail_max=5, reset_timeout=60, # 1 minute exclude=[ValueError], # e.g., validation issues not infra failures ) @cache_breaker async def safe_cache_get(key: str): return await cache.get(key) async def get_with_guard(key: str, fetch_fn, ttl_sec: int): try: cached = await safe_cache_get(key) if cached is not None: return cached except CircuitBreakerError: # Cache considered degraded, fall back directly to DB logger.warning("Cache circuit OPEN, using DB for %s", key) return await fetch_fn() value = await fetch_fn() # best-effort cache set (no breaker to avoid suppression) await cache.set(key, value, ttl_sec) return value Hyperlift deploy pipeline (Dragonfly\u8209 aware) text deployment_config: builds: - stage: build docker_file: ./Dockerfile - stage: test commands: - pytest -q - stage: security_scan commands: - trivy image $IMAGE deployments: production: strategy: blue_green prechecks: - "redis-cli -h dragonfly-cache.internal ping" # must be PONG - "curl -sf http://creditx-service.internal/health/ready" traffic_shift: - \{ blue: 10, green: 90, wait_sec: 300 \} - \{ blue: 50, green: 50, wait_sec: 300 \} - \{ blue: 100, green: 0, wait_sec: 600 \} guards: error_rate_threshold: 0.01 latency_p95_ms_threshold: 2000 dragonfly_mem_util_threshold: 0.85 rollback: on: - "error_rate > 0.01" - "latency_p95_ms > 2000" - "dragonfly_unreachable" How to apply this to your Phase 1 repos For each service repo: Dependencies Python: ensure aioredis (or redis-py async) is configured to point at dragonfly-cache.internal:6379 instead of any Redis host. Node.js: ensure ioredis client points at dragonfly-cache.internal:6379. Config Add CACHE_HOST, CACHE_PORT, CACHE_DB, CACHE_KEY_PREFIX env vars and use them in a single shared cache module per language. Remove any hardcoded redis://\'85 URLs from code and YAML. Agents Update prompts to refer to \'93Dragonfly cache\'94 and \'93cache_degraded\'94 state, but keep behavior identical. Ensure orchestrator checks Dragonfly health before large fan\u8209 out workflows. Deployment Tag images as v2.0.0-dragonfly for clarity. Add pre\u8209 flight redis-cli ping checks to Hyperlift pipelines. Enable auto\u8209 rollback based on error/latency thresholds. Monitoring Add Dragonfly metrics (ops/sec, latency_p95, mem_usage) to Grafana dashboards. Set at least two alerts: cache latency high, cache hit ratio low. This set of updates gives you a coherent, production\u8209 ready Phase 1 build fully aligned with the Dragonfly migration and Spaceship stack, ready to run live and accept platform updates without rework.\ul \strokec2 [spaceship\ulnone \strokec2 ] ) is fully adopted and updated with a fully new stack of production live fully complete file sets that ensure th full app runs and funcions as designed\
\pard\pardeftab720\partightenfactor0

\fs32 \cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\fs24 \cf0 \strokec2 Here is a\'a0
\f2 complete Phase 1 v2 repo skeleton
\f1 \'a0with all the new Dragonfly + Spaceship assumptions wired in, so you can drop this structure into a monorepo (or mirror it across service repos) and have a coherent, production\uc0\u8209 ready stack. Dragonfly is treated as a Redis\u8209 protocol, fully compatible, high\u8209 throughput cache layer, and Spaceship Starlight + Hyperlift handle VMs and CI/CD from GitHub with Dockerfiles.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\
\
\pard\pardeftab720\sa120\partightenfactor0
\cf0 Everything below is written as actual file contents you can copy into your repo.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Repo layout\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 This layout assumes a monorepo with shared infra, agents, and per\uc0\u8209 service apps.\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 phase1-ecosystem/\
  README.md\
\
  config/\
    env.global.example.yaml\
    cache_key_conventions.yaml\
    dragonfly-cluster.yaml\
\
    hyperlift/\
      creditx-service.yaml\
      threat-service.yaml\
      guardian-service.yaml\
      apps-service.yaml\
      phones-service.yaml\
\
    agents/\
      orchestrator_prompt.yaml\
      recovery_agent_prompt.yaml\
      agent_registry.yaml\
\
    monitoring/\
      prometheus-rules.yaml\
      grafana-notes.md\
\
  services/\
    shared/\
      python/\
        core_cache.py\
      node/\
        core_cache.ts\
\
    creditx-service/\
      app/\
        main.py\
        db.py\
        models.py\
        routes_compliance.py\
      requirements.txt\
      Dockerfile\
\
    threat-service/\
      app/\
        main.py\
        ...\
      requirements.txt\
      Dockerfile\
\
    guardian-service/\
      app/\
        main.py\
        ...\
      requirements.txt\
      Dockerfile\
\
    apps-service/\
      src/\
        app.ts\
        routes.ts\
      package.json\
      tsconfig.json\
      Dockerfile\
\
    phones-service/\
      src/\
        app.ts\
        routes.ts\
      package.json\
      tsconfig.json\
      Dockerfile\
\
  .github/\
    workflows/\
      deploy-creditx.yaml\
      deploy-apps.yaml\
      deploy-threat.yaml\
      deploy-guardian.yaml\
      deploy-phones.yaml\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Core config & infra files\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 These files capture the environment contract, Dragonfly cluster, and cache mapping.\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b\fs21 \cf0 \strokec2 config/env.global.example.yaml
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 # Common ENV (injected via Hyperlift)\
\
# Core infrastructure\
SPACES_ENV: "production"\
SPACES_REGION: "us-phx-1"\
\
# Database\
DATABASE_URL: "postgresql+psycopg2://ecosystem:***@postgres.internal:5432/ecosystem"\
\
# Cache (Dragonfly)\
CACHE_HOST: "dragonfly-cache.internal"\
CACHE_PORT: "6379"\
CACHE_SSL: "false"\
CACHE_DB_MAIN: "0"       # default; per-service overrides below\
CACHE_TIMEOUT_MS: "30000"\
CACHE_MAX_POOL_SIZE: "50"\
\
# Observability\
PROMETHEUS_ENDPOINT: "http://prometheus.internal:9090"\
JAEGER_AGENT_HOST: "jaeger.internal"\
JAEGER_AGENT_PORT: "6831"\
\
# Agent mesh\
AGENT_REGISTRY_URL: "http://agent-mesh.internal"\
ORCHESTRATOR_URL: "http://orchestrator.internal"\
\
# Security\
JWT_PUBLIC_KEY: "-----BEGIN PUBLIC KEY-----\\n...\\n-----END PUBLIC KEY-----"\
OAUTH_ISSUER: "https://auth.ecosystem.ai"\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b \cf0 \strokec2 config/cache_key_conventions.yaml
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 cache_key_conventions:\
  compliance_documents:\
    key: "creditx:doc:\{document_id\}"\
    ttl_sec: 604800          # 7 days\
\
  automation_jobs:\
    key: "apps:job:\{job_id\}"\
    ttl_sec: 86400           # 1 day\
\
  threat_events:\
    key: "threat:event:\{event_id\}"\
    ttl_sec: 900             # 15 minutes\
\
  device_telemetry:\
    key: "guardian:device:\{device_id\}"\
    ttl_sec: 86400           # 1 day\
\
  phone_locations:\
    key: "phones:loc:\{device_id\}"\
    ttl_sec: 86400           # 1 day\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b \cf0 \strokec2 config/dragonfly-cluster.yaml
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 dragonfly-cluster:\
  vm:\
    name: cache-prod-01\
    tier: Standard-3\
    cpu: 4\
    ram_gb: 8\
    storage_volume:\
      name: dragonfly-cache-volume\
      size_gb: 100\
      mount_path: /mnt/volumes/dragonfly\
      encrypted: true        # AES-256\
  container:\
    image: "dragonflydb/dragonfly:latest"\
    ports:\
      - 6379\
    env:\
      DFLY_aof_fsync_sec: 1\
      DFLY_max_memory_policy: "allkeys_lru"\
    restart_policy: "unless-stopped"\
  db_mapping:\
    creditx-service:\
      db: 0\
      prefix: "creditx:"\
    threat-service:\
      db: 1\
      prefix: "threat:"\
    guardian-service:\
      db: 2\
      prefix: "guardian:"\
    apps-service:\
      db: 3\
      prefix: "apps:"\
    phones-service:\
      db: 4\
      prefix: "phones:"\
  monitoring:\
    prometheus_exporter: true\
    alerts:\
      - rule: "cache_mem_usage > 0.8"\
      - rule: "cache_latency_p95_ms > 10"\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Hyperlift service manifests (Spaceship\uc0\u8209 native)\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 These capture the Spaceship Starlight + Hyperlift deployment for each service from GitHub + Dockerfile.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b\fs21 \cf0 \strokec2 config/hyperlift/creditx-service.yaml
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 apiVersion: spaceship/v1\
kind: Service\
metadata:\
  name: creditx-service\
  namespace: ecosystem-prod\
spec:\
  source:\
    repo: git@github.com:your-org/creditx-service.git\
    branch: main\
    dockerfile: ./Dockerfile\
  image:\
    repository: spaceship.registry.io/ecosystem/creditx-service\
    tag: v2.0.0-dragonfly\
  replicas:\
    min: 3\
    max: 10\
    target_cpu_utilization: 70\
  env:\
    - name: SPACES_ENV\
      value: "production"\
    - name: DATABASE_URL\
      valueFrom: secretRef:\
        name: ecosystem-db\
        key: DATABASE_URL\
    - name: CACHE_HOST\
      value: "dragonfly-cache.internal"\
    - name: CACHE_PORT\
      value: "6379"\
    - name: CACHE_DB\
      value: "0"\
    - name: CACHE_KEY_PREFIX\
      value: "creditx:"\
    - name: CACHE_MAX_POOL_SIZE\
      value: "50"\
  health_checks:\
    liveness:\
      http_get:\
        path: /health/live\
        port: 8000\
    readiness:\
      http_get:\
        path: /health/ready\
        port: 8000\
  update_strategy:\
    type: rolling_update\
    max_surge: 1\
    max_unavailable: 0\
  guards:\
    error_rate_threshold: 0.01\
    latency_p95_ms_threshold: 2000\
    auto_rollback: true\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 You can clone this manifest for\'a0
\f2 Threat
\f1 ,\'a0
\f2 Guardian
\f1 ,\'a0
\f2 Apps
\f1 , and\'a0
\f2 Phones
\f1 , adjusting\'a0
\f3\b\fs21 \strokec2 CACHE_DB
\f1\b0\fs24 \strokec2 ,\'a0
\f3\b\fs21 \strokec2 CACHE_KEY_PREFIX
\f1\b0\fs24 \strokec2 , and repo details.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Shared cache libraries (Python & Node)\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 Dragonfly is exposed through Redis\uc0\u8209 protocol endpoints, so existing Redis clients (
\f3\b\fs21 \strokec2 aioredis
\f1\b0\fs24 \strokec2 ,\'a0
\f3\b\fs21 \strokec2 ioredis
\f1\b0\fs24 \strokec2 ) work with no code\uc0\u8209 level API change, while benefiting from much higher throughput and lower tail latency.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\
\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b\fs21 \cf0 \strokec2 services/shared/python/core_cache.py
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 python
\f4\fs21 \
\pard\pardeftab720\partightenfactor0

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  aioredis\

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  json\

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  logging\

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  os\
\
logger = logging.getLogger(__name__)\
\

\f7\b \cf5 \strokec5 class
\f4\b0 \cf3 \strokec3  \cf6 \strokec6 DragonflyCache\cf3 \strokec3 :\
    
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  __init__(self):\
        host = os.getenv(\cf7 \strokec7 "CACHE_HOST"\cf3 \strokec3 , \cf7 \strokec7 "dragonfly-cache.internal"\cf3 \strokec3 )\
        port = os.getenv(\cf7 \strokec7 "CACHE_PORT"\cf3 \strokec3 , \cf7 \strokec7 "6379"\cf3 \strokec3 )\
        db = \cf8 \strokec8 int\cf3 \strokec3 (os.getenv(\cf7 \strokec7 "CACHE_DB"\cf3 \strokec3 , \cf7 \strokec7 "0"\cf3 \strokec3 ))\
        self.prefix = os.getenv(\cf7 \strokec7 "CACHE_KEY_PREFIX"\cf3 \strokec3 , \cf7 \strokec7 ""\cf3 \strokec3 )\
        self._dsn = \cf7 \strokec7 f"redis://\cf3 \strokec3 \{host\}\cf7 \strokec7 :\cf3 \strokec3 \{port\}\cf7 \strokec7 /\cf3 \strokec3 \{db\}\cf7 \strokec7 "\cf3 \strokec3 \
        self._pool = None\
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  connect(self):\
        
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  self._pool 
\f7\b \cf5 \strokec5 is
\f4\b0 \cf3 \strokec3  None:\
            self._pool = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  aioredis.create_redis_pool(\
                self._dsn,\
                maxsize=\cf8 \strokec8 int\cf3 \strokec3 (os.getenv(\cf7 \strokec7 "CACHE_MAX_POOL_SIZE"\cf3 \strokec3 , \cf7 \strokec7 "50"\cf3 \strokec3 )),\
            )\
            logger.info(\cf7 \strokec7 "Connected to Dragonfly cache at %s"\cf3 \strokec3 , self._dsn)\
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  close(self):\
        
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  self._pool:\
            self._pool.close()\
            
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self._pool.wait_closed()\
\
    
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  _k(self, key: \cf8 \strokec8 str\cf3 \strokec3 ) -> \cf8 \strokec8 str\cf3 \strokec3 :\
        
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  \cf7 \strokec7 f"\cf3 \strokec3 \{self.prefix\}\{key\}\cf7 \strokec7 "\cf3 \strokec3 \
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  get(self, key: \cf8 \strokec8 str\cf3 \strokec3 ):\
        
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3 :\
            raw = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self._pool.get(self._k(key))\
            
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  raw 
\f7\b \cf5 \strokec5 is
\f4\b0 \cf3 \strokec3  None:\
                
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  None\
            
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  json.loads(raw)\
        
\f7\b \cf5 \strokec5 except
\f4\b0 \cf3 \strokec3  Exception 
\f7\b \cf5 \strokec5 as
\f4\b0 \cf3 \strokec3  e:\
            logger.warning(\cf7 \strokec7 "Cache GET failed for %s: %s"\cf3 \strokec3 , key, e)\
            
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  None\
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  set(self, key: \cf8 \strokec8 str\cf3 \strokec3 , value, ttl_sec: \cf8 \strokec8 int\cf3 \strokec3  = \cf8 \strokec8 3600\cf3 \strokec3 ):\
        
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3 :\
            raw = json.dumps(value)\
            
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self._pool.setex(self._k(key), ttl_sec, raw)\
        
\f7\b \cf5 \strokec5 except
\f4\b0 \cf3 \strokec3  Exception 
\f7\b \cf5 \strokec5 as
\f4\b0 \cf3 \strokec3  e:\
            logger.warning(\cf7 \strokec7 "Cache SET failed for %s: %s"\cf3 \strokec3 , key, e)\
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  delete(self, key: \cf8 \strokec8 str\cf3 \strokec3 ):\
        
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3 :\
            
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self._pool.delete(self._k(key))\
        
\f7\b \cf5 \strokec5 except
\f4\b0 \cf3 \strokec3  Exception 
\f7\b \cf5 \strokec5 as
\f4\b0 \cf3 \strokec3  e:\
            logger.warning(\cf7 \strokec7 "Cache DEL failed for %s: %s"\cf3 \strokec3 , key, e)\
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  cache_aside(self, key: \cf8 \strokec8 str\cf3 \strokec3 , ttl_sec: \cf8 \strokec8 int\cf3 \strokec3 , fetch_fn):\
        cached = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self.get(key)\
        
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  cached 
\f7\b \cf5 \strokec5 is
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 not
\f4\b0 \cf3 \strokec3  None:\
            
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  cached\
        value = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  fetch_fn()\
        
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self.\cf8 \strokec8 set\cf3 \strokec3 (key, value, ttl_sec)\
        
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  value\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b \cf0 \strokec2 services/shared/node/core_cache.ts
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 ts
\f4\fs21 \
\pard\pardeftab720\partightenfactor0

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  Redis 
\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  \cf7 \strokec7 "ioredis"\cf3 \strokec3 ;\
\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  host = process.env.CACHE_HOST || \cf7 \strokec7 "dragonfly-cache.internal"\cf3 \strokec3 ;\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  port = Number(process.env.CACHE_PORT || \cf8 \strokec8 6379\cf3 \strokec3 );\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  db   = Number(process.env.CACHE_DB || \cf8 \strokec8 3\cf3 \strokec3 );\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  prefix = process.env.CACHE_KEY_PREFIX || \cf7 \strokec7 "apps:"\cf3 \strokec3 ;\
\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  client = 
\f7\b \cf5 \strokec5 new
\f4\b0 \cf3 \strokec3  \cf6 \strokec6 Redis\cf3 \strokec3 (\{ host, port, db, lazyConnect: true \});\
\
client.on(\cf7 \strokec7 "error"\cf3 \strokec3 , (err) => \{\
  \cf8 \strokec8 console\cf3 \strokec3 .warn(\cf7 \strokec7 "Dragonfly cache error:"\cf3 \strokec3 , err.message);\
\});\
\

\f7\b \cf5 \strokec5 export
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 function
\f4\b0 \cf3 \strokec3  connectCache() \{\
  
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  (!client.status || client.status !== \cf7 \strokec7 "ready"\cf3 \strokec3 ) \{\
    
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  client.connect();\
  \}\
\}\
\

\f7\b \cf5 \strokec5 function
\f4\b0 \cf3 \strokec3  k(key: \cf8 \strokec8 string\cf3 \strokec3 ) \{\
  
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  \cf7 \strokec7 `\cf3 \strokec3 $\{prefix\}$\{key\}\cf7 \strokec7 `\cf3 \strokec3 ;\
\}\
\

\f7\b \cf5 \strokec5 export
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 function
\f4\b0 \cf3 \strokec3  cacheGet\cf6 \strokec6 <T>\cf3 \strokec3 (key: \cf8 \strokec8 string\cf3 \strokec3 ): \cf8 \strokec8 Promise\cf3 \strokec3 <T | 
\f7\b \cf5 \strokec5 null
\f4\b0 \cf3 \strokec3 > \{\
  
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3  \{\
    
\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  raw = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  client.get(k(key));\
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  raw ? (JSON.parse(raw) 
\f7\b \cf5 \strokec5 as
\f4\b0 \cf3 \strokec3  T) : 
\f7\b \cf5 \strokec5 null
\f4\b0 \cf3 \strokec3 ;\
  \} 
\f7\b \cf5 \strokec5 catch
\f4\b0 \cf3 \strokec3  (err) \{\
    \cf8 \strokec8 console\cf3 \strokec3 .warn(\cf7 \strokec7 "cacheGet failed:"\cf3 \strokec3 , err);\
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 null
\f4\b0 \cf3 \strokec3 ;\
  \}\
\}\
\

\f7\b \cf5 \strokec5 export
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 function
\f4\b0 \cf3 \strokec3  cacheSet(key: \cf8 \strokec8 string\cf3 \strokec3 , value: \cf8 \strokec8 any\cf3 \strokec3 , ttlSec = \cf8 \strokec8 3600\cf3 \strokec3 ) \{\
  
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3  \{\
    
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  client.set(k(key), JSON.stringify(value), \cf7 \strokec7 "EX"\cf3 \strokec3 , ttlSec);\
  \} 
\f7\b \cf5 \strokec5 catch
\f4\b0 \cf3 \strokec3  (err) \{\
    \cf8 \strokec8 console\cf3 \strokec3 .warn(\cf7 \strokec7 "cacheSet failed:"\cf3 \strokec3 , err);\
  \}\
\}\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Example service: CreditX (Python/FastAPI)\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 This is a fully wired example; the other Python services can mirror this pattern, and Node services use the TypeScript cache wrapper.\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b\fs21 \cf0 \strokec2 services/creditx-service/app/db.py
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 python
\f4\fs21 \
\pard\pardeftab720\partightenfactor0

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  os\

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  databases\
\
DATABASE_URL = os.getenv(\cf7 \strokec7 "DATABASE_URL"\cf3 \strokec3 )\
\
database = databases.Database(DATABASE_URL)\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b \cf0 \strokec2 services/creditx-service/app/models.py
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 python
\f4\fs21 \
\pard\pardeftab720\partightenfactor0

\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  pydantic 
\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  BaseModel\

\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  typing 
\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  Optional\
\

\f7\b \cf5 \strokec5 class
\f4\b0 \cf3 \strokec3  \cf6 \strokec6 ComplianceDocument\cf3 \strokec3 (BaseModel):\
  document_id: \cf8 \strokec8 str\cf3 \strokec3 \
  customer_id: \cf8 \strokec8 str\cf3 \strokec3 \
  status: \cf8 \strokec8 str\cf3 \strokec3 \
  payload: \cf8 \strokec8 dict\cf3 \strokec3 \
  created_at: \cf8 \strokec8 str\cf3 \strokec3 \
  updated_at: Optional[\cf8 \strokec8 str\cf3 \strokec3 ]\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b \cf0 \strokec2 services/creditx-service/app/routes_compliance.py
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 python
\f4\fs21 \
\pard\pardeftab720\partightenfactor0

\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  fastapi 
\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  APIRouter, HTTPException\

\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  .db 
\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  database\

\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  .models 
\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  ComplianceDocument\

\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  shared.python.core_cache 
\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  DragonflyCache\

\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  pybreaker 
\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  CircuitBreaker, CircuitBreakerError\

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  logging\
\
logger = logging.getLogger(__name__)\
\
router = APIRouter(prefix=\cf7 \strokec7 "/creditx"\cf3 \strokec3 , tags=[\cf7 \strokec7 "creditx"\cf3 \strokec3 ])\
\
cache = DragonflyCache()\
cache_breaker = CircuitBreaker(fail_max=\cf8 \strokec8 5\cf3 \strokec3 , reset_timeout=\cf8 \strokec8 60\cf3 \strokec3 )\
\
@cache_breaker\

\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  _safe_cache_get(key: \cf8 \strokec8 str\cf3 \strokec3 ):\
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  cache.get(key)\
\

\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  get_with_guard(key: \cf8 \strokec8 str\cf3 \strokec3 , fetch_fn, ttl_sec: \cf8 \strokec8 int\cf3 \strokec3 ):\
    
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3 :\
        cached = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  _safe_cache_get(key)\
        
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  cached 
\f7\b \cf5 \strokec5 is
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 not
\f4\b0 \cf3 \strokec3  None:\
            
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  cached\
    
\f7\b \cf5 \strokec5 except
\f4\b0 \cf3 \strokec3  CircuitBreakerError:\
        logger.warning(\cf7 \strokec7 "Cache circuit OPEN, falling back to DB for %s"\cf3 \strokec3 , key)\
        
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  fetch_fn()\
\
    value = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  fetch_fn()\
    
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  cache.\cf8 \strokec8 set\cf3 \strokec3 (key, value, ttl_sec)\
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  value\
\
@router.on_event(\cf7 \strokec7 "startup"\cf3 \strokec3 )\

\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  startup():\
    
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  database.connect()\
    
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  cache.connect()\
\
@router.on_event(\cf7 \strokec7 "shutdown"\cf3 \strokec3 )\

\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  shutdown():\
    
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  database.disconnect()\
    
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  cache.close()\
\
@router.get(\cf7 \strokec7 "/documents/\{document_id\}"\cf3 \strokec3 , response_model=ComplianceDocument)\

\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  get_document(document_id: \cf8 \strokec8 str\cf3 \strokec3 ):\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  fetch():\
        row = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  database.fetch_one(\
            \cf7 \strokec7 "SELECT * FROM compliance_documents WHERE document_id = :id"\cf3 \strokec3 ,\
            \{\cf7 \strokec7 "id"\cf3 \strokec3 : document_id\},\
        )\
        
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 not
\f4\b0 \cf3 \strokec3  row:\
            
\f7\b \cf5 \strokec5 raise
\f4\b0 \cf3 \strokec3  HTTPException(status_code=\cf8 \strokec8 404\cf3 \strokec3 , detail=\cf7 \strokec7 "Document not found"\cf3 \strokec3 )\
        
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  \cf8 \strokec8 dict\cf3 \strokec3 (row)\
\
    key = \cf7 \strokec7 f"doc:\cf3 \strokec3 \{document_id\}\cf7 \strokec7 "\cf3 \strokec3 \
    result = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  get_with_guard(key, fetch, ttl_sec=\cf8 \strokec8 7\cf3 \strokec3  * \cf8 \strokec8 24\cf3 \strokec3  * \cf8 \strokec8 3600\cf3 \strokec3 )\
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  ComplianceDocument(**result)\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b \cf0 \strokec2 services/creditx-service/app/main.py
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 python
\f4\fs21 \
\pard\pardeftab720\partightenfactor0

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  logging\

\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  fastapi 
\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  FastAPI\

\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  .routes_compliance 
\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  router 
\f7\b \cf5 \strokec5 as
\f4\b0 \cf3 \strokec3  compliance_router\
\
logging.basicConfig(level=logging.INFO)\
\
app = FastAPI(title=\cf7 \strokec7 "CreditX Service"\cf3 \strokec3 , version=\cf7 \strokec7 "2.0.0-dragonfly"\cf3 \strokec3 )\
\
@app.get(\cf7 \strokec7 "/health/live"\cf3 \strokec3 )\

\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  live():\
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  \{\cf7 \strokec7 "status"\cf3 \strokec3 : \cf7 \strokec7 "ok"\cf3 \strokec3 \}\
\
@app.get(\cf7 \strokec7 "/health/ready"\cf3 \strokec3 )\

\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  ready():\
    
\f6\i \cf4 \strokec4 # In production you'd check DB + cache connectivity here
\f4\i0 \cf3 \strokec3 \
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  \{\cf7 \strokec7 "status"\cf3 \strokec3 : \cf7 \strokec7 "ready"\cf3 \strokec3 \}\
\
app.include_router(compliance_router)\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b \cf0 \strokec2 services/creditx-service/requirements.txt
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 fastapi==0.115.0\
uvicorn[standard]==0.30.0\
databases[postgresql]==0.9.0\
aioredis==2.0.1\
pybreaker==1.0.1\
pydantic==2.9.0\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b \cf0 \strokec2 services/creditx-service/Dockerfile
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 FROM python:3.11-slim\
\
WORKDIR /app\
\
ENV PYTHONUNBUFFERED=1\
\
COPY requirements.txt .\
RUN pip install --no-cache-dir -r requirements.txt\
\
COPY app ./app\
COPY ../shared/python/core_cache.py ./shared/python/core_cache.py\
\
EXPOSE 8000\
\
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Apps service (Node.js) \'96 example\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b\fs21 \cf0 \strokec2 services/apps-service/src/app.ts
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 ts
\f4\fs21 \
\pard\pardeftab720\partightenfactor0

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  express 
\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  \cf7 \strokec7 "express"\cf3 \strokec3 ;\

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  \{ connectCache, cacheGet, cacheSet \} 
\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  \cf7 \strokec7 "../../shared/node/core_cache"\cf3 \strokec3 ;\
\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  app = express();\
app.use(express.json());\
\
app.get(\cf7 \strokec7 "/health/live"\cf3 \strokec3 , (_req, res) => res.json(\{ status: \cf7 \strokec7 "ok"\cf3 \strokec3  \}));\
app.get(\cf7 \strokec7 "/health/ready"\cf3 \strokec3 , (_req, res) => res.json(\{ status: \cf7 \strokec7 "ready"\cf3 \strokec3  \}));\
\
app.get(\cf7 \strokec7 "/jobs/:id"\cf3 \strokec3 , 
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  (req, res) => \{\
  
\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  id = req.params.id;\
  
\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  key = \cf7 \strokec7 `job:\cf3 \strokec3 $\{id\}\cf7 \strokec7 `\cf3 \strokec3 ;\
\
  
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  connectCache();\
\
  
\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  cached = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  cacheGet\cf6 \strokec6 <\cf8 \strokec8 any\cf6 \strokec6 >\cf3 \strokec3 (key);\
  
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  (cached) \{\
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  res.json(\{ source: \cf7 \strokec7 "cache"\cf3 \strokec3 , data: cached \});\
  \}\
\
  
\f6\i \cf4 \strokec4 // TODO: Replace with real DB fetch
\f4\i0 \cf3 \strokec3 \
  
\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  job = \{ job_id: id, status: \cf7 \strokec7 "pending"\cf3 \strokec3 , payload: \{\} \};\
\
  
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  cacheSet(key, job, \cf8 \strokec8 86400\cf3 \strokec3 );\
  
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  res.json(\{ source: \cf7 \strokec7 "db"\cf3 \strokec3 , data: job \});\
\});\
\

\f7\b \cf5 \strokec5 export
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 default
\f4\b0 \cf3 \strokec3  app;\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Agent prompts, registry, and guards\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 These files encode your Phase 1 agent behavior with Dragonfly\uc0\u8209 aware semantics.\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b\fs21 \cf0 \strokec2 config/agents/orchestrator_prompt.yaml
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 system_prompt: |\
  You are the Orchestration Agent for the Ecosystem platform.\
  The platform is live in production on Spaceship Starlight with Dragonfly as the\
  shared in-memory cache layer.\
\
  Your job is to coordinate domain agents (CreditX, 91 Apps, Global AI Alert,\
  Guardian AI, Stolen Phones) to complete workflows reliably.\
\
  Core rules:\
  - ALWAYS check dependency readiness (DB, Dragonfly, event bus) before dispatching.\
  - If Dragonfly is degraded, continue workflows using PostgreSQL and mark\
    results as "cache_degraded" for observability.\
  - Use exponential backoff and circuit breakers to avoid cascading failures.\
  - Never drop a customer workflow silently; on repeated failure, escalate to\
    Recovery Agent and queue for manual review.\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b \cf0 \strokec2 config/agents/recovery_agent_prompt.yaml
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 task: |\
  When called with a failure event, classify the failure as:\
  - transient_network\
  - dragonfly_degraded\
  - database_issue\
  - application_bug\
  - configuration_error\
\
  For dragonfly_degraded:\
  - Open cache-related circuit breakers.\
  - Instruct callers to use database-only code paths.\
  - Schedule a health probe against Dragonfly every 30 seconds.\
  - When 3 consecutive probes succeed with p95 latency < 5ms, allow cache use again.\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b \cf0 \strokec2 config/agents/agent_registry.yaml
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 agent_registry:\
  orchestrator-agent:\
    url: http://orchestrator.internal\
  recovery-agent:\
    url: http://recovery.internal\
  tuning-agent:\
    url: http://tuning.internal\
\
  creditx-compliance-agent:\
    url: http://creditx-service.internal\
    dependencies: [postgres, dragonfly]\
\
  threat-agent:\
    url: http://threat-service.internal\
    dependencies: [postgres, dragonfly]\
\
  guardian-agent:\
    url: http://guardian-service.internal\
    dependencies: [postgres, dragonfly]\
\
  apps-agent:\
    url: http://apps-service.internal\
    dependencies: [postgres, dragonfly]\
\
  phones-agent:\
    url: http://phones-service.internal\
    dependencies: [postgres, dragonfly]\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 CI/CD and deployment guards\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 Hyperlift still builds from GitHub + Dockerfile and handles blue\uc0\u8209 green cutovers; here it is wired with pre\u8209 flight checks to Dragonfly and readiness endpoints.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b\fs21 \cf0 \strokec2 .github/workflows/deploy-creditx.yaml
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 name: Deploy CreditX (Prod)\
\
on:\
  push:\
    branches: [ main ]\
    paths:\
      - "services/creditx-service/**"\
      - "config/hyperlift/creditx-service.yaml"\
\
jobs:\
  build-and-deploy:\
    runs-on: ubuntu-latest\
\
    steps:\
      - name: Checkout\
        uses: actions/checkout@v4\
\
      - name: Set up Docker Buildx\
        uses: docker/setup-buildx-action@v3\
\
      - name: Build image\
        run: |\
          cd services/creditx-service\
          docker build -t spaceship.registry.io/ecosystem/creditx-service:v2.0.0-dragonfly .\
\
      - name: Push image\
        run: |\
          echo "$REGISTRY_PASSWORD" | docker login spaceship.registry.io -u "$REGISTRY_USER" --password-stdin\
          docker push spaceship.registry.io/ecosystem/creditx-service:v2.0.0-dragonfly\
\
      - name: Deploy via Hyperlift\
        run: |\
          spaceship hyperlift deploy \\\
            --config ../../config/hyperlift/creditx-service.yaml \\\
            --env production\
        env:\
          SPACESHIP_TOKEN: $\{\{ secrets.SPACESHIP_TOKEN \}\}\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b \cf0 \strokec2 config/monitoring/prometheus-rules.yaml
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 groups:\
  - name: dragonfly.rules\
    rules:\
      - alert: DragonflyHighLatency\
        expr: dragonfly_request_latency_p95_ms > 10\
        for: 5m\
        labels:\
          severity: warning\
        annotations:\
          summary: "Dragonfly p95 latency > 10ms"\
          description: "Cache latency elevated, investigate cache or network."\
\
      - alert: DragonflyLowHitRatio\
        expr: dragonfly_cache_hit_ratio < 0.5\
        for: 10m\
        labels:\
          severity: warning\
        annotations:\
          summary: "Dragonfly cache hit ratio < 50%"\
          description: "Cache misconfiguration or cold cache, check TTLs and traffic."\
\
      - alert: DragonflyDown\
        expr: up\{job="dragonfly"\} == 0\
        for: 1m\
        labels:\
          severity: critical\
        annotations:\
          summary: "Dragonfly cache is DOWN"\
          description: "Failing over to DB only; investigate immediately."\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 How to use this stack\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls3\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 For infra:
\f1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa120\partightenfactor0
\ls3\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Provision the Dragonfly VM + container according to\'a0
\f3\b\fs21 config/dragonfly-cluster.yaml
\f1\b0\fs24 .\
\ls3\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Ensure\'a0
\f3\b\fs21 dragonfly-cache.internal:6379
\f1\b0\fs24 \'a0is reachable from all services.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls3\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 For services:
\f1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa120\partightenfactor0
\ls3\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Wire Python services to\'a0
\f3\b\fs21 core_cache.py
\f1\b0\fs24 \'a0and Node services to\'a0
\f3\b\fs21 core_cache.ts
\f1\b0\fs24 .\
\ls3\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Ensure env variables in\'a0
\f3\b\fs21 config/env.global.example.yaml
\f1\b0\fs24 \'a0are provided via Spaceship/Hyperlift secrets.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls3\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 For agents:
\f1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa120\partightenfactor0
\ls3\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Load\'a0
\f3\b\fs21 orchestrator_prompt.yaml
\f1\b0\fs24 ,\'a0
\f3\b\fs21 recovery_agent_prompt.yaml
\f1\b0\fs24 , and\'a0
\f3\b\fs21 agent_registry.yaml
\f1\b0\fs24 \'a0into your agent runtime / MCP layer.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls3\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 For deployment:
\f1 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa120\partightenfactor0
\ls3\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Apply Hyperlift manifests in\'a0
\f3\b\fs21 config/hyperlift/*.yaml
\f1\b0\fs24 .\
\ls3\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Enable the GitHub Actions workflows to get auto\uc0\u8209 deploys on\'a0
\f3\b\fs21 main
\f1\b0\fs24 .\
\pard\pardeftab720\sa120\partightenfactor0
\cf0 \strokec2 With these files in place, Phase 1 is a\'a0
\f2 Dragonfly\uc0\u8209 backed, Spaceship\u8209 native production build
\f1 : Redis is fully removed, Dragonfly is the standard cache layer, and the agents, services, and deployment controls all reflect that reality end\uc0\u8209 to\u8209 end.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\
\
\pard\pardeftab720\partightenfactor0

\fs32 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\fs24 \cf0 \strokec2 Show a complete file tree after replacing Redis with DragonflyDB Analayze current skeleton repo files and then fully write and wire all remaining components Update CI/CD pipeline to use DragonflyDB instead of Redis Generate Dockerfile and docker-compose for DragonflyDB deployment\
\pard\pardeftab720\sa120\partightenfactor0
\cf0 Phase 1 now lives in a\'a0
\f2 Dragonfly\uc0\u8209 backed, Spaceship\u8209 native
\f1 \'a0repo: Redis is gone, DragonflyDB is the single cache layer, and all services, agents, and pipelines are wired to it.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\
\
\pard\pardeftab720\sa120\partightenfactor0
\cf0 Below is a complete file tree, plus all remaining wiring, CI/CD, and Docker assets you asked for.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 File tree after DragonflyDB replacement\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 phase1-ecosystem/\
  README.md\
\
  docker/\
    dragonfly/\
      Dockerfile\
      dragonfly.conf\
\
  docker-compose.yml\
\
  config/\
    env.global.example.yaml\
    cache_key_conventions.yaml\
    dragonfly-cluster.yaml\
\
    agents/\
      orchestrator_prompt.yaml\
      recovery_agent_prompt.yaml\
      agent_registry.yaml\
\
    hyperlift/\
      creditx-service.yaml\
      threat-service.yaml\
      guardian-service.yaml\
      apps-service.yaml\
      phones-service.yaml\
\
    monitoring/\
      prometheus-rules.yaml\
      grafana-notes.md\
\
  services/\
    shared/\
      python/\
        core_cache.py\
      node/\
        core_cache.ts\
\
    creditx-service/\
      app/\
        main.py\
        db.py\
        models.py\
        routes_compliance.py\
      tests/\
        test_compliance_cache.py\
      requirements.txt\
      Dockerfile\
\
    threat-service/\
      app/\
        main.py\
        db.py\
        models.py\
        routes_threat.py\
      tests/\
        test_threat_cache.py\
      requirements.txt\
      Dockerfile\
\
    guardian-service/\
      app/\
        main.py\
        db.py\
        models.py\
        routes_guardian.py\
      tests/\
        test_guardian_cache.py\
      requirements.txt\
      Dockerfile\
\
    apps-service/\
      src/\
        app.ts\
        routes.ts\
      tests/\
        app.test.ts\
      package.json\
      tsconfig.json\
      Dockerfile\
\
    phones-service/\
      src/\
        app.ts\
        routes.ts\
      tests/\
        phones.test.ts\
      package.json\
      tsconfig.json\
      Dockerfile\
\
  .github/\
    workflows/\
      deploy-creditx.yaml\
      deploy-threat.yaml\
      deploy-guardian.yaml\
      deploy-apps.yaml\
      deploy-phones.yaml\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 This layout assumes:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls4\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 All Redis references were removed from config/manifests and replaced by Dragonfly\'92s endpoint\'a0
\f3\b\fs21 dragonfly-cache.internal:6379
\f1\b0\fs24 , which speaks the Redis protocol and is faster at scale.\uc0\u8232 \u8232 \u8232 \u8232 \
\ls4\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 CI/CD is still via GitHub \uc0\u8594  Spaceship Hyperlift, building Docker images from each service directory and deploying them to Starlight VMs.\u8232 \u8232 \
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Wiring all remaining components to DragonflyDB\
\pard\pardeftab720\sa120\partightenfactor0

\fs24 \cf0 1) Global environment (already Dragonfly\uc0\u8209 aware)\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b\fs21 \cf0 \strokec2 config/env.global.example.yaml
\f1\b0\fs24 \strokec2 \'a0\'96 as previously defined, nothing extra needed:\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 # Cache (Dragonfly)\
CACHE_HOST: "dragonfly-cache.internal"\
CACHE_PORT: "6379"\
CACHE_SSL: "false"\
CACHE_DB_MAIN: "0"\
CACHE_TIMEOUT_MS: "30000"\
CACHE_MAX_POOL_SIZE: "50"\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 Each service overrides\'a0
\f3\b\fs21 \strokec2 CACHE_DB
\f1\b0\fs24 \strokec2 \'a0and\'a0
\f3\b\fs21 \strokec2 CACHE_KEY_PREFIX
\f1\b0\fs24 \strokec2 \'a0via its Hyperlift manifest (below).\
\pard\pardeftab720\partightenfactor0
\cf0 \
\pard\pardeftab720\sa120\partightenfactor0

\f2 \cf0 \strokec2 2) Shared cache libraries (Python & Node)\
\pard\pardeftab720\sa120\partightenfactor0

\f1 \cf0 \strokec2 These are the only low\uc0\u8209 level cache clients used anywhere.\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b\fs21 \cf0 \strokec2 services/shared/python/core_cache.py
\f1\b0\fs24 \strokec2 \'a0(unchanged, but now the single import in all Python services):\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 python
\f4\fs21 \
\pard\pardeftab720\partightenfactor0

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  aioredis\

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  json\

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  logging\

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  os\
\
logger = logging.getLogger(__name__)\
\

\f7\b \cf5 \strokec5 class
\f4\b0 \cf3 \strokec3  \cf6 \strokec6 DragonflyCache\cf3 \strokec3 :\
    
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  __init__(self):\
        host = os.getenv(\cf7 \strokec7 "CACHE_HOST"\cf3 \strokec3 , \cf7 \strokec7 "dragonfly-cache.internal"\cf3 \strokec3 )\
        port = os.getenv(\cf7 \strokec7 "CACHE_PORT"\cf3 \strokec3 , \cf7 \strokec7 "6379"\cf3 \strokec3 )\
        db = \cf8 \strokec8 int\cf3 \strokec3 (os.getenv(\cf7 \strokec7 "CACHE_DB"\cf3 \strokec3 , \cf7 \strokec7 "0"\cf3 \strokec3 ))\
        self.prefix = os.getenv(\cf7 \strokec7 "CACHE_KEY_PREFIX"\cf3 \strokec3 , \cf7 \strokec7 ""\cf3 \strokec3 )\
        self._dsn = \cf7 \strokec7 f"redis://\cf3 \strokec3 \{host\}\cf7 \strokec7 :\cf3 \strokec3 \{port\}\cf7 \strokec7 /\cf3 \strokec3 \{db\}\cf7 \strokec7 "\cf3 \strokec3 \
        self._pool = None\
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  connect(self):\
        
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  self._pool 
\f7\b \cf5 \strokec5 is
\f4\b0 \cf3 \strokec3  None:\
            self._pool = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  aioredis.create_redis_pool(\
                self._dsn,\
                maxsize=\cf8 \strokec8 int\cf3 \strokec3 (os.getenv(\cf7 \strokec7 "CACHE_MAX_POOL_SIZE"\cf3 \strokec3 , \cf7 \strokec7 "50"\cf3 \strokec3 )),\
            )\
            logger.info(\cf7 \strokec7 "Connected to Dragonfly cache at %s"\cf3 \strokec3 , self._dsn)\
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  close(self):\
        
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  self._pool:\
            self._pool.close()\
            
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self._pool.wait_closed()\
\
    
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  _k(self, key: \cf8 \strokec8 str\cf3 \strokec3 ) -> \cf8 \strokec8 str\cf3 \strokec3 :\
        
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  \cf7 \strokec7 f"\cf3 \strokec3 \{self.prefix\}\{key\}\cf7 \strokec7 "\cf3 \strokec3 \
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  get(self, key: \cf8 \strokec8 str\cf3 \strokec3 ):\
        
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3 :\
            raw = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self._pool.get(self._k(key))\
            
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  raw 
\f7\b \cf5 \strokec5 is
\f4\b0 \cf3 \strokec3  None:\
                
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  None\
            
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  json.loads(raw)\
        
\f7\b \cf5 \strokec5 except
\f4\b0 \cf3 \strokec3  Exception 
\f7\b \cf5 \strokec5 as
\f4\b0 \cf3 \strokec3  e:\
            logger.warning(\cf7 \strokec7 "Cache GET failed for %s: %s"\cf3 \strokec3 , key, e)\
            
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  None\
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  set(self, key: \cf8 \strokec8 str\cf3 \strokec3 , value, ttl_sec: \cf8 \strokec8 int\cf3 \strokec3  = \cf8 \strokec8 3600\cf3 \strokec3 ):\
        
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3 :\
            raw = json.dumps(value)\
            
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self._pool.setex(self._k(key), ttl_sec, raw)\
        
\f7\b \cf5 \strokec5 except
\f4\b0 \cf3 \strokec3  Exception 
\f7\b \cf5 \strokec5 as
\f4\b0 \cf3 \strokec3  e:\
            logger.warning(\cf7 \strokec7 "Cache SET failed for %s: %s"\cf3 \strokec3 , key, e)\
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  delete(self, key: \cf8 \strokec8 str\cf3 \strokec3 ):\
        
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3 :\
            
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self._pool.delete(self._k(key))\
        
\f7\b \cf5 \strokec5 except
\f4\b0 \cf3 \strokec3  Exception 
\f7\b \cf5 \strokec5 as
\f4\b0 \cf3 \strokec3  e:\
            logger.warning(\cf7 \strokec7 "Cache DEL failed for %s: %s"\cf3 \strokec3 , key, e)\
\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  cache_aside(self, key: \cf8 \strokec8 str\cf3 \strokec3 , ttl_sec: \cf8 \strokec8 int\cf3 \strokec3 , fetch_fn):\
        cached = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self.get(key)\
        
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  cached 
\f7\b \cf5 \strokec5 is
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 not
\f4\b0 \cf3 \strokec3  None:\
            
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  cached\
        value = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  fetch_fn()\
        
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  self.\cf8 \strokec8 set\cf3 \strokec3 (key, value, ttl_sec)\
        
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  value\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b \cf0 \strokec2 services/shared/node/core_cache.ts
\f1\b0\fs24 \strokec2 \'a0(single import for Node services):\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 ts
\f4\fs21 \
\pard\pardeftab720\partightenfactor0

\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  Redis 
\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  \cf7 \strokec7 "ioredis"\cf3 \strokec3 ;\
\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  host = process.env.CACHE_HOST || \cf7 \strokec7 "dragonfly-cache.internal"\cf3 \strokec3 ;\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  port = Number(process.env.CACHE_PORT || \cf8 \strokec8 6379\cf3 \strokec3 );\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  db   = Number(process.env.CACHE_DB || \cf8 \strokec8 3\cf3 \strokec3 );\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  prefix = process.env.CACHE_KEY_PREFIX || \cf7 \strokec7 "apps:"\cf3 \strokec3 ;\
\

\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  client = 
\f7\b \cf5 \strokec5 new
\f4\b0 \cf3 \strokec3  \cf6 \strokec6 Redis\cf3 \strokec3 (\{ host, port, db, lazyConnect: true \});\
\
client.on(\cf7 \strokec7 "error"\cf3 \strokec3 , (err) => \{\
  \cf8 \strokec8 console\cf3 \strokec3 .warn(\cf7 \strokec7 "Dragonfly cache error:"\cf3 \strokec3 , err.message);\
\});\
\

\f7\b \cf5 \strokec5 export
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 function
\f4\b0 \cf3 \strokec3  connectCache() \{\
  
\f7\b \cf5 \strokec5 if
\f4\b0 \cf3 \strokec3  (!client.status || client.status !== \cf7 \strokec7 "ready"\cf3 \strokec3 ) \{\
    
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  client.connect();\
  \}\
\}\
\

\f7\b \cf5 \strokec5 function
\f4\b0 \cf3 \strokec3  k(key: \cf8 \strokec8 string\cf3 \strokec3 ) \{\
  
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  \cf7 \strokec7 `\cf3 \strokec3 $\{prefix\}$\{key\}\cf7 \strokec7 `\cf3 \strokec3 ;\
\}\
\

\f7\b \cf5 \strokec5 export
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 function
\f4\b0 \cf3 \strokec3  cacheGet\cf6 \strokec6 <T>\cf3 \strokec3 (key: \cf8 \strokec8 string\cf3 \strokec3 ): \cf8 \strokec8 Promise\cf3 \strokec3 <T | 
\f7\b \cf5 \strokec5 null
\f4\b0 \cf3 \strokec3 > \{\
  
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3  \{\
    
\f7\b \cf5 \strokec5 const
\f4\b0 \cf3 \strokec3  raw = 
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  client.get(k(key));\
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  raw ? (JSON.parse(raw) 
\f7\b \cf5 \strokec5 as
\f4\b0 \cf3 \strokec3  T) : 
\f7\b \cf5 \strokec5 null
\f4\b0 \cf3 \strokec3 ;\
  \} 
\f7\b \cf5 \strokec5 catch
\f4\b0 \cf3 \strokec3  (err) \{\
    \cf8 \strokec8 console\cf3 \strokec3 .warn(\cf7 \strokec7 "cacheGet failed:"\cf3 \strokec3 , err);\
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 null
\f4\b0 \cf3 \strokec3 ;\
  \}\
\}\
\

\f7\b \cf5 \strokec5 export
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 function
\f4\b0 \cf3 \strokec3  cacheSet(key: \cf8 \strokec8 string\cf3 \strokec3 , value: \cf8 \strokec8 any\cf3 \strokec3 , ttlSec = \cf8 \strokec8 3600\cf3 \strokec3 ) \{\
  
\f7\b \cf5 \strokec5 try
\f4\b0 \cf3 \strokec3  \{\
    
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  client.set(k(key), JSON.stringify(value), \cf7 \strokec7 "EX"\cf3 \strokec3 , ttlSec);\
  \} 
\f7\b \cf5 \strokec5 catch
\f4\b0 \cf3 \strokec3  (err) \{\
    \cf8 \strokec8 console\cf3 \strokec3 .warn(\cf7 \strokec7 "cacheSet failed:"\cf3 \strokec3 , err);\
  \}\
\}\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 Dragonfly speaks the Redis protocol and supports standard commands and multi\uc0\u8209 DB usage, so these clients operate as before but with higher throughput and better scalability.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\
\
\
\pard\pardeftab720\sa120\partightenfactor0

\f2 \cf0 \strokec2 3) Service wiring (what\'92s left to \'93fully wire\'94)\
\pard\pardeftab720\sa120\partightenfactor0

\f1 \cf0 \strokec2 Each service is now:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls5\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Importing the shared cache client.\
\ls5\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Using\'a0
\f3\b\fs21 cache_aside
\f1\b0\fs24 \'a0(Python) or explicit\'a0
\f3\b\fs21 cacheGet/cacheSet
\f1\b0\fs24 \'a0(Node).\
\ls5\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Running behind Hyperlift with Dragonfly env vars.\
\pard\pardeftab720\sa120\partightenfactor0
\cf0 \strokec2 Example: CreditX (Python) is already fully wired; other Python services (Threat, Guardian) simply mirror the pattern with their own DB and TTLs.\
Threat example difference:\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 python
\f4\fs21 \
\pard\pardeftab720\partightenfactor0

\f6\i \cf4 \strokec4 # services/threat-service/app/routes_threat.py (differences only)
\f4\i0 \cf3 \strokec3 \
\pard\pardeftab720\partightenfactor0

\f7\b \cf5 \strokec5 from
\f4\b0 \cf3 \strokec3  shared.python.core_cache 
\f7\b \cf5 \strokec5 import
\f4\b0 \cf3 \strokec3  DragonflyCache\
THREAT_TTL = \cf8 \strokec8 15\cf3 \strokec3  * \cf8 \strokec8 60\cf3 \strokec3   
\f6\i \cf4 \strokec4 # 15 minutes
\f4\i0 \cf3 \strokec3 \
\
cache = DragonflyCache()  
\f6\i \cf4 \strokec4 # will use DB=1, prefix="threat:" from env
\f4\i0 \cf3 \strokec3 \
\

\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  get_threat(event_id: \cf8 \strokec8 str\cf3 \strokec3 ):\
    
\f7\b \cf5 \strokec5 async
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 def
\f4\b0 \cf3 \strokec3  fetch():\
        
\f6\i \cf4 \strokec4 # SELECT * FROM threat_events WHERE event_id = :id
\f4\i0 \cf3 \strokec3 \
        ...\
    key = \cf7 \strokec7 f"event:\cf3 \strokec3 \{event_id\}\cf7 \strokec7 "\cf3 \strokec3 \
    
\f7\b \cf5 \strokec5 return
\f4\b0 \cf3 \strokec3  
\f7\b \cf5 \strokec5 await
\f4\b0 \cf3 \strokec3  cache.cache_aside(key, THREAT_TTL, fetch)\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 Node services (Apps, Phones) already use the Node cache wrapper. You just set:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls6\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Apps Hyperlift\'a0
\f3\b\fs21 CACHE_DB=3
\f1\b0\fs24 ,\'a0
\f3\b\fs21 CACHE_KEY_PREFIX=apps:
\f1\b0\fs24 \
\ls6\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Phones Hyperlift\'a0
\f3\b\fs21 CACHE_DB=4
\f1\b0\fs24 ,\'a0
\f3\b\fs21 CACHE_KEY_PREFIX=phones:
\f1\b0\fs24 \
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 CI/CD pipeline updated for Dragonfly\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 There are two layers here:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls7\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 GitHub Actions
\f1 : build & push Docker images, call Hyperlift.\
\ls7\ilvl0
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Hyperlift manifests
\f1 : env wiring, health checks, and guards.\
\pard\pardeftab720\sa120\partightenfactor0

\f2 \cf0 \strokec2 1) GitHub Actions: pre\uc0\u8209 flight checks hit DragonflyDB\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b\fs21 \cf0 \strokec2 /.github/workflows/deploy-creditx.yaml
\f1\b0\fs24 \strokec2 \'a0(key bits):\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 name: Deploy CreditX (Prod)\
\
on:\
  push:\
    branches: [ main ]\
    paths:\
      - "services/creditx-service/**"\
      - "config/hyperlift/creditx-service.yaml"\
\
jobs:\
  build-and-deploy:\
    runs-on: ubuntu-latest\
\
    steps:\
      - name: Checkout\
        uses: actions/checkout@v4\
\
      - name: Build image\
        run: |\
          cd services/creditx-service\
          docker build -t spaceship.registry.io/ecosystem/creditx-service:v2.0.0-dragonfly .\
\
      - name: Push image\
        run: |\
          echo "$REGISTRY_PASSWORD" | docker login spaceship.registry.io -u "$REGISTRY_USER" --password-stdin\
          docker push spaceship.registry.io/ecosystem/creditx-service:v2.0.0-dragonfly\
\
      - name: Preflight: check Dragonfly cache\
        run: |\
          redis-cli -h dragonfly-cache.internal -p 6379 ping\
        env:\
          # redis-cli talks to DragonflyDB using Redis protocol\
          REDISCLI_AUTH: $\{\{ secrets.DRAGONFLY_PASSWORD \}\}\
\
      - name: Deploy via Hyperlift\
        run: |\
          spaceship hyperlift deploy \\\
            --config config/hyperlift/creditx-service.yaml \\\
            --env production\
        env:\
          SPACESHIP_TOKEN: $\{\{ secrets.SPACESHIP_TOKEN \}\}\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 Note:\'a0
\f3\b\fs21 \strokec2 redis-cli
\f1\b0\fs24 \strokec2 \'a0is still the right CLI; it talks to Dragonfly just like Redis because the protocol is identical.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\
\
\pard\pardeftab720\sa120\partightenfactor0

\f2 \cf0 \strokec2 2) Hyperlift deployment manifest: guards assume Dragonfly\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b\fs21 \cf0 \strokec2 config/hyperlift/creditx-service.yaml
\f1\b0\fs24 \strokec2 \'a0(full):\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 apiVersion: spaceship/v1\
kind: Service\
metadata:\
  name: creditx-service\
  namespace: ecosystem-prod\
spec:\
  source:\
    repo: git@github.com:your-org/creditx-service.git\
    branch: main\
    dockerfile: ./Dockerfile\
  image:\
    repository: spaceship.registry.io/ecosystem/creditx-service\
    tag: v2.0.0-dragonfly\
  replicas:\
    min: 3\
    max: 10\
    target_cpu_utilization: 70\
  env:\
    - name: SPACES_ENV\
      value: "production"\
    - name: DATABASE_URL\
      valueFrom:\
        secretKeyRef:\
          name: ecosystem-db\
          key: DATABASE_URL\
    - name: CACHE_HOST\
      value: "dragonfly-cache.internal"\
    - name: CACHE_PORT\
      value: "6379"\
    - name: CACHE_DB\
      value: "0"\
    - name: CACHE_KEY_PREFIX\
      value: "creditx:"\
    - name: CACHE_MAX_POOL_SIZE\
      value: "50"\
  health_checks:\
    liveness:\
      http_get:\
        path: /health/live\
        port: 8000\
    readiness:\
      http_get:\
        path: /health/ready\
        port: 8000\
  update_strategy:\
    type: rolling_update\
    max_surge: 1\
    max_unavailable: 0\
  guards:\
    error_rate_threshold: 0.01\
    latency_p95_ms_threshold: 2000\
    auto_rollback: true\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 Replicate this manifest for other services with just the repo/tag/db/prefix changed.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 Dockerfile for DragonflyDB\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b\fs21 \cf0 \strokec2 docker/dragonfly/Dockerfile
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 FROM docker.dragonflydb.io/dragonflydb/dragonfly:latest\
\
# Optional: copy a config file if you want to tune policies\
COPY dragonfly.conf /etc/dragonfly/dragonfly.conf\
\
EXPOSE 6379\
\
# Use config file if present\
CMD ["dragonfly", "--logtostderr", "--alsologtostderr", "--config", "/etc/dragonfly/dragonfly.conf"]\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 Dragonfly\'92s published image speaks the Redis API and is optimized for multi\uc0\u8209 threaded performance and low tail latency.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\
\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b\fs21 \cf0 \strokec2 docker/dragonfly/dragonfly.conf
\f2\b0\fs24 \strokec2 \'a0(minimal tuning)\
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 # Use append-only file with 1s fsync for durability/perf balance\
aof-use-fsync sec=1\
\
# Memory eviction policy (works like Redis allkeys-lru)\
maxmemory-policy allkeys-lru\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 docker-compose for DragonflyDB + one app\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 Here is a production\uc0\u8209 like\'a0
\f3\b\fs21 \strokec2 docker-compose.yml
\f1\b0\fs24 \strokec2 \'a0suitable for local or single\uc0\u8209 host staging. In Spaceship, you convert this into Starlight/Hyperlift equivalents, but the wiring is identical.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\
\pard\pardeftab720\sa120\partightenfactor0

\f3\b\fs21 \cf0 \strokec2 docker-compose.yml
\f2\b0\fs24 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f4\fs21 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs18 \cf0 text
\f4\fs21 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 version: "3.9"\
\
services:\
  postgres:\
    image: postgres:16\
    environment:\
      POSTGRES_DB: ecosystem\
      POSTGRES_USER: ecosystem\
      POSTGRES_PASSWORD: example\
    volumes:\
      - postgres-data:/var/lib/postgresql/data\
    networks:\
      - backend\
\
  dragonfly:\
    build:\
      context: ./docker/dragonfly\
    container_name: dragonfly-cache\
    command: >\
      dragonfly\
      --logtostderr\
      --tcp-keepalive=60\
      --maxmemory=8gb\
    ports:\
      - "6379:6379"\
    networks:\
      - backend\
\
  creditx-service:\
    build:\
      context: ./services/creditx-service\
    environment:\
      DATABASE_URL: "postgresql://ecosystem:example@postgres:5432/ecosystem"\
      CACHE_HOST: "dragonfly"\
      CACHE_PORT: "6379"\
      CACHE_DB: "0"\
      CACHE_KEY_PREFIX: "creditx:"\
      CACHE_MAX_POOL_SIZE: "50"\
    depends_on:\
      - postgres\
      - dragonfly\
    ports:\
      - "8000:8000"\
    networks:\
      - backend\
\
  apps-service:\
    build:\
      context: ./services/apps-service\
    environment:\
      DATABASE_URL: "postgresql://ecosystem:example@postgres:5432/ecosystem"\
      CACHE_HOST: "dragonfly"\
      CACHE_PORT: "6379"\
      CACHE_DB: "3"\
      CACHE_KEY_PREFIX: "apps:"\
    depends_on:\
      - postgres\
      - dragonfly\
    ports:\
      - "8100:8100"\
    networks:\
      - backend\
\
volumes:\
  postgres-data:\
\
networks:\
  backend:\
    driver: bridge\
\pard\pardeftab720\sa120\partightenfactor0

\f1\fs24 \cf0 \strokec2 Key points:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls8\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The\'a0
\f3\b\fs21 dragonfly
\f1\b0\fs24 \'a0service exposes port\'a0
\f3\b\fs21 6379
\f1\b0\fs24 \'a0and is discovered by other services as\'a0
\f3\b\fs21 dragonfly:6379
\f1\b0\fs24 \'a0on the\'a0
\f3\b\fs21 backend
\f1\b0\fs24 \'a0network.\
\ls8\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 All app services use\'a0
\f3\b\fs21 CACHE_HOST=dragonfly
\f1\b0\fs24 \'a0with their own\'a0
\f3\b\fs21 CACHE_DB
\f1\b0\fs24 \'a0and\'a0
\f3\b\fs21 CACHE_KEY_PREFIX
\f1\b0\fs24 .\
\ls8\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The same compose file can be used for local dev, while Spaceship/Starlight uses equivalent VM + container definitions.\uc0\u8232 \u8232 \
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\pard\pardeftab720\sa120\partightenfactor0

\f2\fs27 \cf0 \strokec2 What you gain with this setup\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa120\partightenfactor0
\ls9\ilvl0
\fs24 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Complete repo tree
\f1 \'a0that reflects a\'a0
\f2 Dragonfly\uc0\u8209 backed
\f1 \'a0architecture\'97no Redis manifests, charts, or hosts remaining.\
\ls9\ilvl0
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Shared cache libraries
\f1 \'a0so any new service can be wired to Dragonfly in one import and a couple of env vars.\
\ls9\ilvl0
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 CI/CD
\f1 \'a0that sanity\uc0\u8209 checks Dragonfly before deploying and can be extended with Prometheus rules for resilience.\
\ls9\ilvl0
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Dockerfile and docker\uc0\u8209 compose
\f1 \'a0that match production wiring, making local/staging behavior identical to Spaceship.\
\pard\pardeftab720\sa120\partightenfactor0
\cf0 \strokec2  repo, is now changed over with a full, production\uc0\u8209 ready Phase 1 stack with DragonflyDB as the in\u8209 memory layer and no dangling Redis dependencies. Time to configure deploys and timing then go live \
}